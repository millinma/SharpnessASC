[mdirenv: loading /nas/staff/data_work/manuel/cloned_repos/visualisation/.envrc
[mdirenv: loading ~/myVisualisationEnv/.envrc
[mdirenv: using flake path:/home/milliman/myVisualisationEnv/.nix
[mdirenv: nix-direnv: using cached dev shell
[38;5;202mðŸ”¨ Welcome to DeepLearningGPU[0m

[1m[general commands][0m

  julia  - High-level, high-performance, dynamic language for technical computing
  menu   - prints this menu
  poetry - Python dependency management and packaging made easy.

direnv: export +CPPFLAGS +DEVSHELL_DIR +IN_NIX_SHELL +JULIA_PROJECT +LDFLAGS +NIXPKGS_PATH +POETRY_VIRTUALENVS_IN_PROJECT +PRJ_DATA_DIR +PRJ_ROOT +VIRTUAL_ENV +VIRTUAL_ENV_PROMPT +XLA_FLAGS +name ~LD_LIBRARY_PATH ~PATH ~XDG_DATA_DIRS
Grid Search Module
Running 84 total experiments.

Running experiment 1/84

Running NeuralBench with Configuration:
device:		 cuda:0
state:		 None
approach:	 cnn10
category:	 None
batch_size:	 16
epochs:		 50
learning_rate:	 0.001
seed:		 42
optimizer:	 KFACOptimizer
exclude cities:	 None

-----------------hi---------------
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_train.csv
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_evaluate.csv
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_evaluate.csv
Dev results at epoch 1:
UAR: 0.3223575848575848
ACC: 0.3224393530997305
F1: 0.3052614267699442
train_loss: 2.516087262900834
val_loss: 1.7521259784698486

Dev results at epoch 2:
UAR: 0.3376217126217126
ACC: 0.3376010781671159
F1: 0.3275655795734087
train_loss: 1.597947133638878
val_loss: 1.7125624418258667

Dev results at epoch 3:
UAR: 0.40149808899808903
ACC: 0.40161725067385445
F1: 0.3775085713115115
train_loss: 1.447705449585516
val_loss: 1.644509196281433

Dev results at epoch 4:
UAR: 0.4072538447538447
ACC: 0.40734501347708896
F1: 0.3972291322779584
train_loss: 1.3179107086491886
val_loss: 1.6630833148956299

Dev results at epoch 5:
UAR: 0.4106288106288106
ACC: 0.4107142857142857
F1: 0.4151275306862431
train_loss: 1.2064010090571224
val_loss: 1.6217726469039917

Dev results at epoch 6:
UAR: 0.436551324051324
ACC: 0.4366576819407008
F1: 0.4193417005228627
train_loss: 1.1066101534806303
val_loss: 1.625840663909912

Dev results at epoch 7:
UAR: 0.44396783146783153
ACC: 0.4440700808625337
F1: 0.43072401280340145
train_loss: 1.0361496158891528
val_loss: 1.5560978651046753

Dev results at epoch 8:
UAR: 0.456466693966694
ACC: 0.45653638814016173
F1: 0.44075164266996214
train_loss: 0.9546215231066307
val_loss: 1.607167363166809

Dev results at epoch 9:
UAR: 0.49352079352079353
ACC: 0.49359838274932616
F1: 0.49377315821438666
train_loss: 0.8809330006645307
val_loss: 1.4468274116516113

Dev results at epoch 10:
UAR: 0.49689348439348435
ACC: 0.4969676549865229
F1: 0.48887133264201943
train_loss: 0.8121322784636849
val_loss: 1.4808084964752197

Dev results at epoch 11:
UAR: 0.493526481026481
ACC: 0.49359838274932616
F1: 0.49175459354992457
train_loss: 0.7549686239518114
val_loss: 1.5405101776123047

Dev results at epoch 12:
UAR: 0.49724952224952224
ACC: 0.4973045822102426
F1: 0.49046010423786884
train_loss: 0.7145029248377438
val_loss: 1.5445743799209595

Dev results at epoch 13:
UAR: 0.509378696878697
ACC: 0.5094339622641509
F1: 0.5061912539515128
train_loss: 0.6872682671605653
val_loss: 1.5511714220046997

Dev results at epoch 14:
UAR: 0.516478978978979
ACC: 0.5165094339622641
F1: 0.5106053733257062
train_loss: 0.6295609757355398
val_loss: 1.5607887506484985

Dev results at epoch 15:
UAR: 0.49749863499863495
ACC: 0.49764150943396224
F1: 0.48394617435534687
train_loss: 0.5909614755269588
val_loss: 1.721329927444458

Dev results at epoch 16:
UAR: 0.4989227864227865
ACC: 0.49898921832884097
F1: 0.4930233601023814
train_loss: 0.564241950813028
val_loss: 1.6639920473098755

Dev results at epoch 17:
UAR: 0.4598860223860224
ACC: 0.45990566037735847
F1: 0.4605323133357106
train_loss: 0.5231096788233771
val_loss: 1.8781180381774902

Dev results at epoch 18:
UAR: 0.5319649194649194
ACC: 0.5320080862533693
F1: 0.527935821704975
train_loss: 0.4935916625176645
val_loss: 1.592724084854126

Dev results at epoch 19:
UAR: 0.5363397488397489
ACC: 0.5363881401617251
F1: 0.5375188800611823
train_loss: 0.45306778450806934
val_loss: 1.6631230115890503

Dev results at epoch 20:
UAR: 0.5117492492492494
ACC: 0.5117924528301887
F1: 0.5088071299559208
train_loss: 0.41430032287403207
val_loss: 1.8429055213928223

Dev results at epoch 21:
UAR: 0.5488101738101739
ACC: 0.5488544474393531
F1: 0.5498763837797668
train_loss: 0.3911664365190172
val_loss: 1.6483659744262695

Dev results at epoch 22:
UAR: 0.5029859404859406
ACC: 0.503032345013477
F1: 0.5061563300022922
train_loss: 0.380842763179527
val_loss: 1.8258482217788696

Dev results at epoch 23:
UAR: 0.5164425789425791
ACC: 0.5165094339622641
F1: 0.5140708229333832
train_loss: 0.35728783486464316
val_loss: 1.8123862743377686

Dev results at epoch 24:
UAR: 0.5235280735280735
ACC: 0.5235849056603774
F1: 0.5232636483969553
train_loss: 0.34869660508156436
val_loss: 1.8699817657470703

Dev results at epoch 25:
UAR: 0.5245063245063245
ACC: 0.5245956873315364
F1: 0.5181629373688472
train_loss: 0.3141699334839092
val_loss: 1.8833508491516113

Dev results at epoch 26:
UAR: 0.5258974883974885
ACC: 0.5259433962264151
F1: 0.5242288439449057
train_loss: 0.2951871464060959
val_loss: 2.045736789703369

Dev results at epoch 27:
UAR: 0.5345811720811722
ACC: 0.5347035040431267
F1: 0.5278638692236631
train_loss: 0.28696652424584684
val_loss: 1.9296658039093018

Dev results at epoch 28:
UAR: 0.535012285012285
ACC: 0.5350404312668463
F1: 0.5319955995886911
train_loss: 0.2810274525454859
val_loss: 2.008978843688965

Dev results at epoch 29:
UAR: 0.5136921011921013
ACC: 0.5138140161725068
F1: 0.5072639248243968
train_loss: 0.25552882765551
val_loss: 2.2027461528778076

Dev results at epoch 30:
UAR: 0.4767836017836017
ACC: 0.47675202156334234
F1: 0.46439127271241887
train_loss: 0.23591808856487326
val_loss: 2.6080853939056396

Dev results at epoch 31:
UAR: 0.5003787878787879
ACC: 0.5003369272237197
F1: 0.49935399865903235
train_loss: 0.23954899295127577
val_loss: 2.2979655265808105

Dev results at epoch 32:
UAR: 0.5249203749203748
ACC: 0.5249326145552561
F1: 0.5251101208915555
train_loss: 0.2131962522316003
val_loss: 2.207934856414795

Dev results at epoch 33:
UAR: 0.5352807352807354
ACC: 0.535377358490566
F1: 0.522522988662989
train_loss: 0.21961499640733037
val_loss: 2.1980714797973633

Dev results at epoch 34:
UAR: 0.5401253526253527
ACC: 0.5400943396226415
F1: 0.5431796415088537
train_loss: 0.19446688575735732
val_loss: 2.0818614959716797

Dev results at epoch 35:
UAR: 0.5369903994903995
ACC: 0.5370619946091644
F1: 0.5331374900825363
train_loss: 0.19098491068046117
val_loss: 2.131314992904663

Dev results at epoch 36:
UAR: 0.5457264082264083
ACC: 0.545822102425876
F1: 0.5382925185122132
train_loss: 0.19856801907716476
val_loss: 2.1162357330322266

Dev results at epoch 37:
UAR: 0.5484074984074983
ACC: 0.5485175202156334
F1: 0.546661319863343
train_loss: 0.17115634305105
val_loss: 2.1430935859680176

Dev results at epoch 38:
UAR: 0.5268893893893895
ACC: 0.5269541778975741
F1: 0.520172317715392
train_loss: 0.18182087631870536
val_loss: 2.383230209350586

Dev results at epoch 39:
UAR: 0.5303018928018928
ACC: 0.5303234501347709
F1: 0.5270697738001315
train_loss: 0.16055008898585724
val_loss: 2.410742998123169

Dev results at epoch 40:
UAR: 0.5262489762489763
ACC: 0.5262803234501348
F1: 0.5181251629845935
train_loss: 0.176468763631936
val_loss: 2.4403295516967773

Dev results at epoch 41:
UAR: 0.5322390572390573
ACC: 0.532345013477089
F1: 0.5294434787840694
train_loss: 0.181066828702266
val_loss: 2.303814649581909

Dev results at epoch 42:
UAR: 0.5167406042406043
ACC: 0.5168463611859838
F1: 0.5123566883195692
train_loss: 0.1653655299877925
val_loss: 2.4481029510498047

Dev results at epoch 43:
UAR: 0.5221369096369097
ACC: 0.5222371967654986
F1: 0.5192859546681249
train_loss: 0.1239749226478576
val_loss: 2.429964065551758

Dev results at epoch 44:
UAR: 0.5511170261170262
ACC: 0.5512129380053908
F1: 0.5445863833773619
train_loss: 0.1785634383952612
val_loss: 2.198768138885498

Dev results at epoch 45:
UAR: 0.5258952133952135
ACC: 0.5259433962264151
F1: 0.52542155566601
train_loss: 0.1400515428543697
val_loss: 2.4062817096710205

Dev results at epoch 46:
UAR: 0.5346403221403222
ACC: 0.5347035040431267
F1: 0.5288191292308767
train_loss: 0.13705061857664866
val_loss: 2.4918384552001953

Dev results at epoch 47:
UAR: 0.5292952042952043
ACC: 0.5293126684636119
F1: 0.5286494006516201
train_loss: 0.14236366405597978
val_loss: 2.3661556243896484

Dev results at epoch 48:
UAR: 0.5481936481936482
ACC: 0.5481805929919138
F1: 0.5477634825513094
train_loss: 0.12936890625087108
val_loss: 2.3087410926818848

Dev results at epoch 49:
UAR: 0.5535399035399035
ACC: 0.5535714285714286
F1: 0.5515443311386958
train_loss: 0.14029540696624349
val_loss: 2.2156338691711426

Dev results at epoch 50:
UAR: 0.5457741832741834
ACC: 0.545822102425876
F1: 0.5429849602528154
train_loss: 0.11725932942212101
val_loss: 2.3470253944396973

Best dev results found at epoch 49:
UAR: 0.5535399035399035
ACC: 0.5535714285714286
F1: 0.5515443311386958
train_loss: 0.14029540696624349
val_loss: 2.2156338691711426

Best test results:
UAR: 0.5535399035399035
ACC: 0.5535714285714286
F1: 0.5515443311386958

Running experiment 2/84

Running NeuralBench with Configuration:
device:		 cuda:0
state:		 None
approach:	 cnn10
category:	 None
batch_size:	 16
epochs:		 50
learning_rate:	 0.001
seed:		 42
optimizer:	 GDTUO-Adam-Adam
exclude cities:	 None

-----------------hi---------------
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_train.csv
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_evaluate.csv
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_evaluate.csv
Dev results at epoch 1:
UAR: 0.33406815906815907
ACC: 0.33423180592991913
F1: 0.2993860572688749
train_loss: 2.1008226338940386
val_loss: 1.7492997646331787

Dev results at epoch 2:
UAR: 0.3932295932295933
ACC: 0.39319407008086255
F1: 0.37831272530151067
train_loss: 1.5617277437195882
val_loss: 1.6140429973602295

Dev results at epoch 3:
UAR: 0.4048878423878424
ACC: 0.4049865229110512
F1: 0.3687084874231702
train_loss: 1.4180989222428233
val_loss: 1.6101359128952026

Dev results at epoch 4:
UAR: 0.4355969605969606
ACC: 0.4356469002695418
F1: 0.4138084148782976
train_loss: 1.3194101623516585
val_loss: 1.5038371086120605

Dev results at epoch 5:
UAR: 0.46052188552188555
ACC: 0.46057951482479786
F1: 0.4537457126400343
train_loss: 1.237112167911158
val_loss: 1.513996958732605

Dev results at epoch 6:
UAR: 0.4851317226317226
ACC: 0.48517520215633425
F1: 0.46165903632865674
train_loss: 1.1180331351284583
val_loss: 1.4165685176849365

Dev results at epoch 7:
UAR: 0.5060321685321686
ACC: 0.5060646900269542
F1: 0.4940532963775489
train_loss: 1.074938306386528
val_loss: 1.3330756425857544

Dev results at epoch 8:
UAR: 0.4986133861133862
ACC: 0.49865229110512127
F1: 0.4701461040044932
train_loss: 0.9946458913206645
val_loss: 1.4077998399734497

Dev results at epoch 9:
UAR: 0.5336632086632086
ACC: 0.5336927223719676
F1: 0.5115339382682474
train_loss: 0.9762512363177668
val_loss: 1.28363835811615

Dev results at epoch 10:
UAR: 0.5282691782691783
ACC: 0.5283018867924528
F1: 0.5093313395620969
train_loss: 0.93479803996534
val_loss: 1.3038713932037354

Dev results at epoch 11:
UAR: 0.5562471562471563
ACC: 0.556266846361186
F1: 0.5420453732115277
train_loss: 0.8558533114529421
val_loss: 1.2755584716796875

Dev results at epoch 12:
UAR: 0.5417394667394667
ACC: 0.5417789757412399
F1: 0.5201099828729986
train_loss: 0.839306762828177
val_loss: 1.3049182891845703

Dev results at epoch 13:
UAR: 0.5609666484666485
ACC: 0.5609838274932615
F1: 0.5443509540224821
train_loss: 0.7656252498888888
val_loss: 1.2674875259399414

Dev results at epoch 14:
UAR: 0.519586632086632
ACC: 0.5195417789757413
F1: 0.49299677071471654
train_loss: 0.837764788602499
val_loss: 1.3367969989776611

Dev results at epoch 15:
UAR: 0.5710744835744836
ACC: 0.5710916442048517
F1: 0.5546158893735192
train_loss: 0.709663473129409
val_loss: 1.220909833908081

Dev results at epoch 16:
UAR: 0.5218639093639094
ACC: 0.5219002695417789
F1: 0.5008630591195076
train_loss: 0.6980187256584736
val_loss: 1.4100884199142456

Dev results at epoch 17:
UAR: 0.5275935025935026
ACC: 0.5276280323450134
F1: 0.5061542928651824
train_loss: 0.6688367275335535
val_loss: 1.327728509902954

Dev results at epoch 18:
UAR: 0.577524115024115
ACC: 0.5774932614555256
F1: 0.5677035630242541
train_loss: 0.7198786833851608
val_loss: 1.1830322742462158

Dev results at epoch 19:
UAR: 0.579446491946492
ACC: 0.5795148247978437
F1: 0.5705809826235779
train_loss: 0.6733954446934343
val_loss: 1.2082760334014893

Dev results at epoch 20:
UAR: 0.5673252798252798
ACC: 0.5673854447439353
F1: 0.5502461504717876
train_loss: 0.5837491757032661
val_loss: 1.3207324743270874

Dev results at epoch 21:
UAR: 0.5852261352261353
ACC: 0.5852425876010782
F1: 0.5734517851870768
train_loss: 0.5600217638658904
val_loss: 1.2183672189712524

Dev results at epoch 22:
UAR: 0.5818579943579943
ACC: 0.5818733153638814
F1: 0.5703653388660391
train_loss: 0.5374552805706397
val_loss: 1.2160462141036987

Dev results at epoch 23:
UAR: 0.5919339794339794
ACC: 0.5919811320754716
F1: 0.5849219737932859
train_loss: 0.5123478533936939
val_loss: 1.1833175420761108

Dev results at epoch 24:
UAR: 0.5313882063882064
ACC: 0.5313342318059299
F1: 0.5101731047470441
train_loss: 0.5429295363482878
val_loss: 1.4729735851287842

Dev results at epoch 25:
UAR: 0.5003958503958503
ACC: 0.5003369272237197
F1: 0.48102828737212455
train_loss: 0.47862889305320394
val_loss: 1.7137553691864014

Dev results at epoch 26:
UAR: 0.5740558740558741
ACC: 0.5741239892183289
F1: 0.5609692336652164
train_loss: 0.4620824121749551
val_loss: 1.3273448944091797

Dev results at epoch 27:
UAR: 0.579047229047229
ACC: 0.579177897574124
F1: 0.564845250498808
train_loss: 0.4227303835090766
val_loss: 1.2679580450057983

Dev results at epoch 28:
UAR: 0.5768302393302394
ACC: 0.5768194070080862
F1: 0.5670080741534449
train_loss: 0.46712981779789736
val_loss: 1.304290533065796

Dev results at epoch 29:
UAR: 0.5949551824551824
ACC: 0.5950134770889488
F1: 0.5851478356709648
train_loss: 0.46706623266550273
val_loss: 1.2509503364562988

Dev results at epoch 30:
UAR: 0.5956831831831833
ACC: 0.5956873315363881
F1: 0.5824009528146143
train_loss: 0.409370315571626
val_loss: 1.3407434225082397

Dev results at epoch 31:
UAR: 0.5781770406770406
ACC: 0.578167115902965
F1: 0.571249795283225
train_loss: 0.38705302982293455
val_loss: 1.3863619565963745

Dev results at epoch 32:
UAR: 0.5788527163527164
ACC: 0.5788409703504043
F1: 0.5691363906648367
train_loss: 0.43741866547661273
val_loss: 1.32790207862854

Dev results at epoch 33:
UAR: 0.5771339521339522
ACC: 0.5771563342318059
F1: 0.5620259159857859
train_loss: 0.3683835240411663
val_loss: 1.3649044036865234

Dev results at epoch 34:
UAR: 0.5973166348166348
ACC: 0.5973719676549866
F1: 0.5907020833434846
train_loss: 0.31240604304519715
val_loss: 1.2586199045181274

Dev results at epoch 35:
UAR: 0.5885521885521886
ACC: 0.5886118598382749
F1: 0.576288762238093
train_loss: 0.330943086904656
val_loss: 1.3377902507781982

Dev results at epoch 36:
UAR: 0.5784466284466283
ACC: 0.5785040431266847
F1: 0.5576410184420094
train_loss: 0.30375100043682296
val_loss: 1.4830302000045776

Dev results at epoch 37:
UAR: 0.5629322504322505
ACC: 0.5630053908355795
F1: 0.5544681018148818
train_loss: 0.3006774759024621
val_loss: 1.5649197101593018

Dev results at epoch 38:
UAR: 0.6121905996905996
ACC: 0.6121967654986523
F1: 0.6053190413073599
train_loss: 0.29151123511217714
val_loss: 1.2417080402374268

Dev results at epoch 39:
UAR: 0.5825848575848577
ACC: 0.5825471698113207
F1: 0.56923310199324
train_loss: 0.27960786968896345
val_loss: 1.4619076251983643

Dev results at epoch 40:
UAR: 0.5865945490945491
ACC: 0.5865902964959568
F1: 0.5719755298574457
train_loss: 0.29610093545172905
val_loss: 1.3456594944000244

Dev results at epoch 41:
UAR: 0.5926312676312675
ACC: 0.592654986522911
F1: 0.5875468837074753
train_loss: 0.3340531500677268
val_loss: 1.3288897275924683

Dev results at epoch 42:
UAR: 0.44844958594958595
ACC: 0.44845013477088946
F1: 0.4181920593840367
train_loss: 0.2446762208356378
val_loss: 2.5019209384918213

Dev results at epoch 43:
UAR: 0.5478432978432978
ACC: 0.5478436657681941
F1: 0.530039624422322
train_loss: 0.24779376494703562
val_loss: 1.735209584236145

Dev results at epoch 44:
UAR: 0.5932637182637183
ACC: 0.5933288409703504
F1: 0.5789004302045645
train_loss: 0.2434017287582193
val_loss: 1.4735310077667236

Dev results at epoch 45:
UAR: 0.596990171990172
ACC: 0.5970350404312669
F1: 0.5824598462960474
train_loss: 0.2429779503528639
val_loss: 1.4649766683578491

Dev results at epoch 46:
UAR: 0.5680237055237056
ACC: 0.5680592991913747
F1: 0.5508309438472436
train_loss: 0.23745377519661892
val_loss: 1.63973069190979

Dev results at epoch 47:
UAR: 0.5771419146419147
ACC: 0.5771563342318059
F1: 0.5663214714325796
train_loss: 0.22830160797060492
val_loss: 1.6220911741256714

Dev results at epoch 48:
UAR: 0.6007462007462008
ACC: 0.6007412398921833
F1: 0.5932164017140713
train_loss: 0.2157632573641077
val_loss: 1.4621707201004028

Dev results at epoch 49:
UAR: 0.596992446992447
ACC: 0.5970350404312669
F1: 0.5986525529392945
train_loss: 0.24330084859996284
val_loss: 1.3841514587402344

Dev results at epoch 50:
UAR: 0.6020907270907271
ACC: 0.602088948787062
F1: 0.5964126781329591
train_loss: 0.20318019103988544
val_loss: 1.4050090312957764

Best dev results found at epoch 38:
UAR: 0.6121905996905996
ACC: 0.6121967654986523
F1: 0.6053190413073599
train_loss: 0.29151123511217714
val_loss: 1.2417080402374268

Best test results:
UAR: 0.6121905996905996
ACC: 0.6121967654986523
F1: 0.6053190413073599

Running experiment 3/84

Running NeuralBench with Configuration:
device:		 cuda:0
state:		 None
approach:	 cnn10
category:	 None
batch_size:	 16
epochs:		 50
learning_rate:	 0.001
seed:		 42
optimizer:	 Adam
exclude cities:	 None

-----------------hi---------------
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_train.csv
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_evaluate.csv
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_evaluate.csv
Dev results at epoch 1:
UAR: 0.3158806533806534
ACC: 0.3160377358490566
F1: 0.27986312888619
train_loss: 2.031309609697174
val_loss: 1.7874624729156494

Dev results at epoch 2:
UAR: 0.38657293657293657
ACC: 0.386455525606469
F1: 0.345222803867523
train_loss: 1.5391086409591728
val_loss: 1.6427687406539917

Dev results at epoch 3:
UAR: 0.34690940940940945
ACC: 0.3470350404312669
F1: 0.3031886975068535
train_loss: 1.445863320928532
val_loss: 1.8189078569412231

Dev results at epoch 4:
UAR: 0.3952122577122577
ACC: 0.3952156334231806
F1: 0.37023584409620874
train_loss: 1.3803672090701904
val_loss: 1.6327781677246094

Dev results at epoch 5:
UAR: 0.40080421330421334
ACC: 0.4009433962264151
F1: 0.39682563625397227
train_loss: 1.3055648368112274
val_loss: 1.6745771169662476

Dev results at epoch 6:
UAR: 0.42505005005005003
ACC: 0.4252021563342318
F1: 0.3918771099812376
train_loss: 1.250552582986576
val_loss: 1.5906277894973755

Dev results at epoch 7:
UAR: 0.42814746564746564
ACC: 0.4282345013477089
F1: 0.41712307651052216
train_loss: 1.1863050159037045
val_loss: 1.5458979606628418

Dev results at epoch 8:
UAR: 0.44499613249613246
ACC: 0.4450808625336927
F1: 0.42225348078449026
train_loss: 1.1063342318706906
val_loss: 1.5531110763549805

Dev results at epoch 9:
UAR: 0.4433706433706434
ACC: 0.44339622641509435
F1: 0.42656024090784445
train_loss: 1.0304679896550217
val_loss: 1.575899600982666

Dev results at epoch 10:
UAR: 0.4854251979251979
ACC: 0.4855121293800539
F1: 0.4743471433206503
train_loss: 0.9689292869821856
val_loss: 1.4320471286773682

Dev results at epoch 11:
UAR: 0.47192419692419685
ACC: 0.4720350404312669
F1: 0.4605279837797651
train_loss: 0.9148489632489072
val_loss: 1.483839511871338

Dev results at epoch 12:
UAR: 0.4895281645281645
ACC: 0.48955525606469
F1: 0.474763680270605
train_loss: 0.8687636394988221
val_loss: 1.5050550699234009

Dev results at epoch 13:
UAR: 0.48613727363727366
ACC: 0.4861859838274933
F1: 0.4802796029475506
train_loss: 0.8179561887341813
val_loss: 1.4759902954101562

Dev results at epoch 14:
UAR: 0.4861691236691238
ACC: 0.4861859838274933
F1: 0.4698351048910653
train_loss: 0.7809875598102637
val_loss: 1.4906787872314453

Dev results at epoch 15:
UAR: 0.49115251615251615
ACC: 0.4912398921832884
F1: 0.47023129915954665
train_loss: 0.7363749735168302
val_loss: 1.5373928546905518

Dev results at epoch 16:
UAR: 0.485436572936573
ACC: 0.4855121293800539
F1: 0.4687543252118072
train_loss: 0.7059200889636834
val_loss: 1.5352317094802856

Dev results at epoch 17:
UAR: 0.47976954226954227
ACC: 0.4797843665768194
F1: 0.46763596530529544
train_loss: 0.6696879481736737
val_loss: 1.5676589012145996

Dev results at epoch 18:
UAR: 0.5101999726999727
ACC: 0.5101078167115903
F1: 0.5014413644388727
train_loss: 0.6382751767816959
val_loss: 1.4336072206497192

Dev results at epoch 19:
UAR: 0.49176449176449166
ACC: 0.4919137466307278
F1: 0.4790088545966881
train_loss: 0.6045626998971828
val_loss: 1.6555813550949097

Dev results at epoch 20:
UAR: 0.5013843388843389
ACC: 0.5013477088948787
F1: 0.4926455585517525
train_loss: 0.5614072857307268
val_loss: 1.523260474205017

Dev results at epoch 21:
UAR: 0.5134395759395759
ACC: 0.5134770889487871
F1: 0.50845545890927
train_loss: 0.5288138918553021
val_loss: 1.5693581104278564

Dev results at epoch 22:
UAR: 0.512429474929475
ACC: 0.512466307277628
F1: 0.5116972309818217
train_loss: 0.5072694347674221
val_loss: 1.534011721611023

Dev results at epoch 23:
UAR: 0.5246132496132496
ACC: 0.5245956873315364
F1: 0.517166883842491
train_loss: 0.4802261359417834
val_loss: 1.5908432006835938

Dev results at epoch 24:
UAR: 0.5087894712894714
ACC: 0.5087601078167115
F1: 0.4970772320429047
train_loss: 0.4606311897718415
val_loss: 1.7166290283203125

Dev results at epoch 25:
UAR: 0.5302984802984803
ACC: 0.5303234501347709
F1: 0.5205857100819302
train_loss: 0.43585389990782003
val_loss: 1.5524033308029175

Dev results at epoch 26:
UAR: 0.5362487487487487
ACC: 0.5363881401617251
F1: 0.5197244032627091
train_loss: 0.40338502939735016
val_loss: 1.7549710273742676

Dev results at epoch 27:
UAR: 0.5352750477750478
ACC: 0.535377358490566
F1: 0.5234384120558493
train_loss: 0.38975340564055677
val_loss: 1.7243833541870117

Dev results at epoch 28:
UAR: 0.5346983346983347
ACC: 0.5347035040431267
F1: 0.5331896660718682
train_loss: 0.36537160814866715
val_loss: 1.6196470260620117

Dev results at epoch 29:
UAR: 0.5349508599508599
ACC: 0.5350404312668463
F1: 0.5232101325326771
train_loss: 0.3502955465915721
val_loss: 1.8258991241455078

Dev results at epoch 30:
UAR: 0.5107607607607607
ACC: 0.5107816711590296
F1: 0.4995282010989904
train_loss: 0.3377765915447255
val_loss: 1.9216686487197876

Dev results at epoch 31:
UAR: 0.5053860678860679
ACC: 0.5053908355795148
F1: 0.5013325878028847
train_loss: 0.30554895961330725
val_loss: 1.9175834655761719

Dev results at epoch 32:
UAR: 0.516428928928929
ACC: 0.5165094339622641
F1: 0.5155918498051968
train_loss: 0.3081015120777819
val_loss: 1.8633006811141968

Dev results at epoch 33:
UAR: 0.525864500864501
ACC: 0.5259433962264151
F1: 0.5181421966210065
train_loss: 0.2788375326936887
val_loss: 1.8627898693084717

Dev results at epoch 34:
UAR: 0.5421455546455546
ACC: 0.5421159029649596
F1: 0.5308480246530982
train_loss: 0.2605198367145702
val_loss: 1.9070048332214355

Dev results at epoch 35:
UAR: 0.5049083174083174
ACC: 0.5050539083557951
F1: 0.4883769309966106
train_loss: 0.25181239331194455
val_loss: 2.122314691543579

Dev results at epoch 36:
UAR: 0.5411172536172536
ACC: 0.5411051212938005
F1: 0.5322249193014795
train_loss: 0.2416205585391217
val_loss: 1.886665940284729

Dev results at epoch 37:
UAR: 0.5218184093184093
ACC: 0.5219002695417789
F1: 0.5171252599864572
train_loss: 0.2173622461731406
val_loss: 2.1193742752075195

Dev results at epoch 38:
UAR: 0.5346710346710346
ACC: 0.5347035040431267
F1: 0.529515647627578
train_loss: 0.21364611708095035
val_loss: 1.9825551509857178

Dev results at epoch 39:
UAR: 0.5377718627718628
ACC: 0.5377358490566038
F1: 0.5213608029568372
train_loss: 0.1966582249998321
val_loss: 2.157752275466919

Dev results at epoch 40:
UAR: 0.5393711893711893
ACC: 0.5394204851752021
F1: 0.533356589682384
train_loss: 0.19193038965985051
val_loss: 1.9412909746170044

Dev results at epoch 41:
UAR: 0.5437710437710438
ACC: 0.543800539083558
F1: 0.5369338095374757
train_loss: 0.20343640255757778
val_loss: 2.0311102867126465

Dev results at epoch 42:
UAR: 0.5211586586586587
ACC: 0.5212264150943396
F1: 0.514161511757653
train_loss: 0.16741988721265236
val_loss: 2.1076879501342773

Dev results at epoch 43:
UAR: 0.5232607607607608
ACC: 0.5232479784366577
F1: 0.5205761476716828
train_loss: 0.1703416179187643
val_loss: 2.0152676105499268

Dev results at epoch 44:
UAR: 0.5363101738101738
ACC: 0.5363881401617251
F1: 0.5222984962690187
train_loss: 0.16772245981528894
val_loss: 2.220082998275757

Dev results at epoch 45:
UAR: 0.5285899535899535
ACC: 0.5286388140161725
F1: 0.5191077945514989
train_loss: 0.17099438159393715
val_loss: 2.186469554901123

Dev results at epoch 46:
UAR: 0.5201565201565203
ACC: 0.5202156334231806
F1: 0.520362732333284
train_loss: 0.14346187591247628
val_loss: 2.2166225910186768

Dev results at epoch 47:
UAR: 0.5384316134316134
ACC: 0.5384097035040432
F1: 0.5278196971902127
train_loss: 0.15432711742511115
val_loss: 2.149312973022461

Dev results at epoch 48:
UAR: 0.5552177177177178
ACC: 0.555256064690027
F1: 0.5484242053360304
train_loss: 0.12931463234649304
val_loss: 2.091583728790283

Dev results at epoch 49:
UAR: 0.5249124124124124
ACC: 0.5249326145552561
F1: 0.5209430417823209
train_loss: 0.154989813465784
val_loss: 2.3990414142608643

Dev results at epoch 50:
UAR: 0.516163891163891
ACC: 0.5161725067385444
F1: 0.5105139090121036
train_loss: 0.12208306594772578
val_loss: 2.563000440597534

Best dev results found at epoch 48:
UAR: 0.5552177177177178
ACC: 0.555256064690027
F1: 0.5484242053360304
train_loss: 0.12931463234649304
val_loss: 2.091583728790283

Best test results:
UAR: 0.5552177177177178
ACC: 0.555256064690027
F1: 0.5484242053360304

Running experiment 4/84

Running NeuralBench with Configuration:
device:		 cuda:0
state:		 None
approach:	 cnn10
category:	 None
batch_size:	 16
epochs:		 50
learning_rate:	 0.001
seed:		 42
optimizer:	 SGD
exclude cities:	 None

-----------------hi---------------
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_train.csv
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_evaluate.csv
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_evaluate.csv
Dev results at epoch 1:
UAR: 0.3128401128401128
ACC: 0.3130053908355795
F1: 0.27309897379697007
train_loss: 1.7498263918793624
val_loss: 1.9653719663619995

Dev results at epoch 2:
UAR: 0.4012535262535263
ACC: 0.40128032345013476
F1: 0.36413386222108024
train_loss: 1.3618105910761114
val_loss: 1.6985461711883545

Dev results at epoch 3:
UAR: 0.4288367913367913
ACC: 0.42890835579514824
F1: 0.3894222323022686
train_loss: 1.2220447069590854
val_loss: 1.6454416513442993

Dev results at epoch 4:
UAR: 0.49229001729001737
ACC: 0.49225067385444743
F1: 0.46401142802051387
train_loss: 1.1182562762109685
val_loss: 1.4143896102905273

Dev results at epoch 5:
UAR: 0.5032168532168532
ACC: 0.5033692722371967
F1: 0.4920365242936061
train_loss: 1.0197447673220268
val_loss: 1.4190722703933716

Dev results at epoch 6:
UAR: 0.4796978796978797
ACC: 0.4797843665768194
F1: 0.4483445336528987
train_loss: 0.9614952434993691
val_loss: 1.5610183477401733

Dev results at epoch 7:
UAR: 0.5104991354991355
ACC: 0.5104447439353099
F1: 0.5000889867410862
train_loss: 0.8999513071222404
val_loss: 1.3982038497924805

Dev results at epoch 8:
UAR: 0.4826849576849576
ACC: 0.4828167115902965
F1: 0.47455144534907684
train_loss: 0.8445010160321086
val_loss: 1.5743536949157715

Dev results at epoch 9:
UAR: 0.5292542542542542
ACC: 0.5293126684636119
F1: 0.5162651362338979
train_loss: 0.8081023019716093
val_loss: 1.3325577974319458

Dev results at epoch 10:
UAR: 0.5366787241787241
ACC: 0.5367250673854448
F1: 0.5251027456416273
train_loss: 0.753746284481313
val_loss: 1.2933475971221924

Dev results at epoch 11:
UAR: 0.465571253071253
ACC: 0.465633423180593
F1: 0.45475294760240353
train_loss: 0.7195301186656078
val_loss: 1.8556535243988037

Dev results at epoch 12:
UAR: 0.5410956410956411
ACC: 0.5411051212938005
F1: 0.5201914882916222
train_loss: 0.6922164664850202
val_loss: 1.3837977647781372

Dev results at epoch 13:
UAR: 0.5377388752388753
ACC: 0.5377358490566038
F1: 0.5270619148301489
train_loss: 0.6673665679777884
val_loss: 1.406240463256836

Dev results at epoch 14:
UAR: 0.5417747292747294
ACC: 0.5417789757412399
F1: 0.5207585141422244
train_loss: 0.634081201608648
val_loss: 1.4449007511138916

Dev results at epoch 15:
UAR: 0.5387512512512511
ACC: 0.5387466307277629
F1: 0.5245721476939185
train_loss: 0.6072952094971109
val_loss: 1.4652949571609497

Dev results at epoch 16:
UAR: 0.5313108563108562
ACC: 0.5313342318059299
F1: 0.5140148932598085
train_loss: 0.596125672499885
val_loss: 1.4775429964065552

Dev results at epoch 17:
UAR: 0.5209072709072708
ACC: 0.52088948787062
F1: 0.49804527663014975
train_loss: 0.5571958574830188
val_loss: 1.5920997858047485

Dev results at epoch 18:
UAR: 0.5597461097461097
ACC: 0.5596361185983828
F1: 0.5547111383817284
train_loss: 0.5375853846316895
val_loss: 1.422788381576538

Dev results at epoch 19:
UAR: 0.5669226044226046
ACC: 0.5670485175202157
F1: 0.5620647613513082
train_loss: 0.5136758891133781
val_loss: 1.3843263387680054

Dev results at epoch 20:
UAR: 0.5767870142870143
ACC: 0.5768194070080862
F1: 0.5694172652813388
train_loss: 0.47731871352470207
val_loss: 1.3865408897399902

Dev results at epoch 21:
UAR: 0.5750693875693875
ACC: 0.5751347708894878
F1: 0.5639227146463157
train_loss: 0.4598033312678269
val_loss: 1.4764443635940552

Dev results at epoch 22:
UAR: 0.5365410865410865
ACC: 0.5367250673854448
F1: 0.5201925004806445
train_loss: 0.44472166650074046
val_loss: 1.586302399635315

Dev results at epoch 23:
UAR: 0.5744517244517244
ACC: 0.5744609164420486
F1: 0.5701274103220836
train_loss: 0.4215890180665193
val_loss: 1.467562198638916

Dev results at epoch 24:
UAR: 0.5256108381108381
ACC: 0.5256064690026954
F1: 0.5035699399882216
train_loss: 0.41464916143015895
val_loss: 1.7205814123153687

Dev results at epoch 25:
UAR: 0.49237419237419233
ACC: 0.49225067385444743
F1: 0.46618871228333064
train_loss: 0.38836732646717104
val_loss: 2.215879440307617

Dev results at epoch 26:
UAR: 0.5709607334607335
ACC: 0.5710916442048517
F1: 0.5650100036611817
train_loss: 0.36039819405814216
val_loss: 1.5395888090133667

Dev results at epoch 27:
UAR: 0.5237874237874237
ACC: 0.523921832884097
F1: 0.5000322086140774
train_loss: 0.34946485895573887
val_loss: 1.7625017166137695

Dev results at epoch 28:
UAR: 0.5731754481754481
ACC: 0.5731132075471698
F1: 0.565167712067508
train_loss: 0.3459912118974557
val_loss: 1.5605056285858154

Dev results at epoch 29:
UAR: 0.5626205751205751
ACC: 0.5626684636118598
F1: 0.5482538819149733
train_loss: 0.3361818545624904
val_loss: 1.636995792388916

Dev results at epoch 30:
UAR: 0.5424833924833924
ACC: 0.5424528301886793
F1: 0.5271791103713768
train_loss: 0.3176993126175521
val_loss: 1.7031731605529785

Dev results at epoch 31:
UAR: 0.5542167167167167
ACC: 0.5542452830188679
F1: 0.548742145390829
train_loss: 0.29833400727837495
val_loss: 1.7002983093261719

Dev results at epoch 32:
UAR: 0.5464669214669214
ACC: 0.5464959568733153
F1: 0.5423957909988746
train_loss: 0.2994703770319655
val_loss: 1.6605188846588135

Dev results at epoch 33:
UAR: 0.5828191828191829
ACC: 0.5828840970350404
F1: 0.5771520457417929
train_loss: 0.27861413963454834
val_loss: 1.5789345502853394

Dev results at epoch 34:
UAR: 0.5462280462280462
ACC: 0.5461590296495957
F1: 0.537824723463733
train_loss: 0.2614934347113349
val_loss: 1.8376741409301758

Dev results at epoch 35:
UAR: 0.5654233779233779
ACC: 0.5653638814016172
F1: 0.5561269960249847
train_loss: 0.25486055619050274
val_loss: 1.6432615518569946

Dev results at epoch 36:
UAR: 0.5781736281736282
ACC: 0.578167115902965
F1: 0.5667880037756261
train_loss: 0.25309219792323084
val_loss: 1.6834144592285156

Dev results at epoch 37:
UAR: 0.58247906997907
ACC: 0.5825471698113207
F1: 0.5791486557017439
train_loss: 0.23498701719932027
val_loss: 1.6258193254470825

Dev results at epoch 38:
UAR: 0.5758303758303758
ACC: 0.5758086253369272
F1: 0.5672665550689805
train_loss: 0.2336515018386811
val_loss: 1.615859031677246

Dev results at epoch 39:
UAR: 0.5707684957684956
ACC: 0.5707547169811321
F1: 0.5583127189200131
train_loss: 0.21675482651545214
val_loss: 1.7448033094406128

Dev results at epoch 40:
UAR: 0.5737350987350986
ACC: 0.5737870619946092
F1: 0.5641561317995331
train_loss: 0.20254017593592985
val_loss: 1.7717787027359009

Dev results at epoch 41:
UAR: 0.5747053872053872
ACC: 0.5747978436657682
F1: 0.570627181254802
train_loss: 0.20185803807311758
val_loss: 1.6901203393936157

Dev results at epoch 42:
UAR: 0.5592467467467468
ACC: 0.5592991913746631
F1: 0.5507873989413279
train_loss: 0.1930515562834374
val_loss: 1.8355833292007446

Dev results at epoch 43:
UAR: 0.5495540995540995
ACC: 0.5495283018867925
F1: 0.5420384466845463
train_loss: 0.18115548859323713
val_loss: 1.9732366800308228

Dev results at epoch 44:
UAR: 0.54242537992538
ACC: 0.5424528301886793
F1: 0.5309296813961495
train_loss: 0.17635352845289845
val_loss: 2.065298557281494

Dev results at epoch 45:
UAR: 0.5457548457548458
ACC: 0.545822102425876
F1: 0.5311571281737649
train_loss: 0.1916923357210072
val_loss: 2.049913167953491

Dev results at epoch 46:
UAR: 0.5706354081354081
ACC: 0.5707547169811321
F1: 0.5589545228835091
train_loss: 0.16236577179114348
val_loss: 1.9697751998901367

Dev results at epoch 47:
UAR: 0.5312983437983437
ACC: 0.5313342318059299
F1: 0.5235897012662241
train_loss: 0.175530975956026
val_loss: 2.2612380981445312

Dev results at epoch 48:
UAR: 0.5835949585949586
ACC: 0.5835579514824798
F1: 0.5729803943476464
train_loss: 0.15977252406235634
val_loss: 1.8560830354690552

Dev results at epoch 49:
UAR: 0.5808046683046683
ACC: 0.5808625336927223
F1: 0.5831282830433319
train_loss: 0.15393356999029265
val_loss: 1.7499043941497803

Dev results at epoch 50:
UAR: 0.5629868504868505
ACC: 0.5630053908355795
F1: 0.5590080067534992
train_loss: 0.13964699742006606
val_loss: 1.9481515884399414

Best dev results found at epoch 48:
UAR: 0.5835949585949586
ACC: 0.5835579514824798
F1: 0.5729803943476464
train_loss: 0.15977252406235634
val_loss: 1.8560830354690552

Best test results:
UAR: 0.5835949585949586
ACC: 0.5835579514824798
F1: 0.5729803943476464

Running experiment 5/84

Running NeuralBench with Configuration:
device:		 cuda:0
state:		 None
approach:	 cnn10
category:	 None
batch_size:	 16
epochs:		 50
learning_rate:	 0.001
seed:		 43
optimizer:	 KFACOptimizer
exclude cities:	 None

-----------------hi---------------
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_train.csv
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_evaluate.csv
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_evaluate.csv
Dev results at epoch 1:
UAR: 0.3116684866684867
ACC: 0.3116576819407008
F1: 0.26513205766542847
train_loss: 2.4736213972205285
val_loss: 1.8864755630493164

Dev results at epoch 2:
UAR: 0.3445877695877696
ACC: 0.3446765498652291
F1: 0.32983664894024856
train_loss: 1.64561919105012
val_loss: 1.845777988433838

Dev results at epoch 3:
UAR: 0.35742674492674487
ACC: 0.35747978436657685
F1: 0.34952647327805153
train_loss: 1.4524680307094446
val_loss: 1.7529735565185547

Dev results at epoch 4:
UAR: 0.39889321139321143
ACC: 0.39892183288409705
F1: 0.37123633695967084
train_loss: 1.3322040789588894
val_loss: 1.6881769895553589

Dev results at epoch 5:
UAR: 0.4561686686686686
ACC: 0.45619946091644203
F1: 0.4487446807349074
train_loss: 1.2275599611310752
val_loss: 1.4724433422088623

Dev results at epoch 6:
UAR: 0.4800789425789425
ACC: 0.4801212938005391
F1: 0.46086596438452015
train_loss: 1.1301562399320721
val_loss: 1.4176849126815796

Dev results at epoch 7:
UAR: 0.43358927108927114
ACC: 0.4336253369272237
F1: 0.42403427323150933
train_loss: 1.0540626560426387
val_loss: 1.6485002040863037

Dev results at epoch 8:
UAR: 0.4959288834288834
ACC: 0.49595687331536387
F1: 0.4835414575301421
train_loss: 0.987625159109854
val_loss: 1.3890199661254883

Dev results at epoch 9:
UAR: 0.5131347256347256
ACC: 0.5131401617250674
F1: 0.4974277403599993
train_loss: 0.9061749462477803
val_loss: 1.3685684204101562

Dev results at epoch 10:
UAR: 0.5188461188461189
ACC: 0.5188679245283019
F1: 0.5016807625415217
train_loss: 0.8531092472741421
val_loss: 1.4812626838684082

Dev results at epoch 11:
UAR: 0.5262546637546638
ACC: 0.5262803234501348
F1: 0.515351672176745
train_loss: 0.7800705464640024
val_loss: 1.377179741859436

Dev results at epoch 12:
UAR: 0.5221949221949221
ACC: 0.5222371967654986
F1: 0.512527353316523
train_loss: 0.7340668345474023
val_loss: 1.3494452238082886

Dev results at epoch 13:
UAR: 0.5121553371553371
ACC: 0.5121293800539084
F1: 0.5097260447064278
train_loss: 0.6774212718009949
val_loss: 1.5102694034576416

Dev results at epoch 14:
UAR: 0.5353796978796979
ACC: 0.535377358490566
F1: 0.5265066052301688
train_loss: 0.6618185135165714
val_loss: 1.3964271545410156

Dev results at epoch 15:
UAR: 0.5329681954681955
ACC: 0.5330188679245284
F1: 0.5325050210711366
train_loss: 0.6177048417744904
val_loss: 1.3813459873199463

Dev results at epoch 16:
UAR: 0.5265936390936391
ACC: 0.5266172506738545
F1: 0.5166488047409278
train_loss: 0.5768996686818674
val_loss: 1.5678412914276123

Dev results at epoch 17:
UAR: 0.5384600509600509
ACC: 0.5384097035040432
F1: 0.5240643917695784
train_loss: 0.5507512503695106
val_loss: 1.4040045738220215

Dev results at epoch 18:
UAR: 0.5016163891163891
ACC: 0.5016846361185984
F1: 0.4920056963966548
train_loss: 0.5228895488977091
val_loss: 1.6277281045913696

Dev results at epoch 19:
UAR: 0.5373259623259623
ACC: 0.5373989218328841
F1: 0.5347460518519463
train_loss: 0.5002579183231309
val_loss: 1.4896684885025024

Dev results at epoch 20:
UAR: 0.5222188097188097
ACC: 0.5222371967654986
F1: 0.5203139086164736
train_loss: 0.4753875937931589
val_loss: 1.6184271574020386

Dev results at epoch 21:
UAR: 0.5430453180453181
ACC: 0.5431266846361186
F1: 0.5307201597691001
train_loss: 0.43648918498337336
val_loss: 1.5229870080947876

Dev results at epoch 22:
UAR: 0.5417519792519793
ACC: 0.5417789757412399
F1: 0.537955612612945
train_loss: 0.41318326466476796
val_loss: 1.5728356838226318

Dev results at epoch 23:
UAR: 0.5343525343525343
ACC: 0.534366576819407
F1: 0.5256351388225525
train_loss: 0.3870374809348911
val_loss: 1.6988635063171387

Dev results at epoch 24:
UAR: 0.5373828373828374
ACC: 0.5373989218328841
F1: 0.5288794345167035
train_loss: 0.38787231581522424
val_loss: 1.7848211526870728

Dev results at epoch 25:
UAR: 0.5460767585767585
ACC: 0.5461590296495957
F1: 0.5348639009145935
train_loss: 0.36063421030506443
val_loss: 1.7350765466690063

Dev results at epoch 26:
UAR: 0.5491855491855493
ACC: 0.5491913746630728
F1: 0.5427855843046261
train_loss: 0.33968724721118826
val_loss: 1.7396713495254517

Dev results at epoch 27:
UAR: 0.5296262171262172
ACC: 0.5296495956873315
F1: 0.5230664419410767
train_loss: 0.30807586793253305
val_loss: 1.7985984086990356

Dev results at epoch 28:
UAR: 0.5478819728819728
ACC: 0.5478436657681941
F1: 0.5407444520808024
train_loss: 0.2964065638429486
val_loss: 1.7337901592254639

Dev results at epoch 29:
UAR: 0.5575996450996452
ACC: 0.5576145552560647
F1: 0.5466896999179903
train_loss: 0.28957642504853653
val_loss: 1.7721660137176514

Dev results at epoch 30:
UAR: 0.5333083083083083
ACC: 0.5333557951482479
F1: 0.520708813574187
train_loss: 0.2792183050570022
val_loss: 1.9860765933990479

Dev results at epoch 31:
UAR: 0.5660524160524161
ACC: 0.5660377358490566
F1: 0.5623047470106963
train_loss: 0.2713206779171221
val_loss: 1.8665305376052856

Dev results at epoch 32:
UAR: 0.5238784238784239
ACC: 0.523921832884097
F1: 0.5147086497514678
train_loss: 0.2503877098721165
val_loss: 2.0496041774749756

Dev results at epoch 33:
UAR: 0.5394121394121394
ACC: 0.5394204851752021
F1: 0.531913911023768
train_loss: 0.24742490221732397
val_loss: 1.9554849863052368

Dev results at epoch 34:
UAR: 0.5282623532623533
ACC: 0.5283018867924528
F1: 0.5209383230169337
train_loss: 0.2259646053329955
val_loss: 2.175219774246216

Dev results at epoch 35:
UAR: 0.5494551369551369
ACC: 0.5495283018867925
F1: 0.540880181772223
train_loss: 0.21448470349370247
val_loss: 1.960111141204834

Dev results at epoch 36:
UAR: 0.5370131495131496
ACC: 0.5370619946091644
F1: 0.5159383295483029
train_loss: 0.2203635077001815
val_loss: 2.1559338569641113

Dev results at epoch 37:
UAR: 0.557554145054145
ACC: 0.5576145552560647
F1: 0.5528086881610418
train_loss: 0.19794063124232814
val_loss: 1.9393131732940674

Dev results at epoch 38:
UAR: 0.5274888524888526
ACC: 0.5276280323450134
F1: 0.5190220170972978
train_loss: 0.19986647787266001
val_loss: 2.345592975616455

Dev results at epoch 39:
UAR: 0.5359893984893985
ACC: 0.5360512129380054
F1: 0.5288209322005242
train_loss: 0.18879232188379488
val_loss: 2.2796170711517334

Dev results at epoch 40:
UAR: 0.5336848211848213
ACC: 0.5336927223719676
F1: 0.5306642919336697
train_loss: 0.1874113366880453
val_loss: 2.2117538452148438

Dev results at epoch 41:
UAR: 0.567012467012467
ACC: 0.5670485175202157
F1: 0.5572570308547137
train_loss: 0.1863305527153601
val_loss: 2.036763906478882

Dev results at epoch 42:
UAR: 0.5565588315588317
ACC: 0.5566037735849056
F1: 0.5559521153752873
train_loss: 0.1649864194085256
val_loss: 2.0603222846984863

Dev results at epoch 43:
UAR: 0.5363966238966238
ACC: 0.5363881401617251
F1: 0.5324988066074107
train_loss: 0.17584823634804045
val_loss: 2.2409424781799316

Dev results at epoch 44:
UAR: 0.5652925652925653
ACC: 0.5653638814016172
F1: 0.5598446928611417
train_loss: 0.16420519589650512
val_loss: 2.231290578842163

Dev results at epoch 45:
UAR: 0.5481083356083356
ACC: 0.5481805929919138
F1: 0.5441713983958194
train_loss: 0.17469824202273912
val_loss: 2.181223154067993

Dev results at epoch 46:
UAR: 0.5380824005824006
ACC: 0.5380727762803235
F1: 0.5297026720245281
train_loss: 0.15084676869359734
val_loss: 2.35725474357605

Dev results at epoch 47:
UAR: 0.5522101647101647
ACC: 0.5522237196765498
F1: 0.550375686998539
train_loss: 0.1540283232915721
val_loss: 2.151402711868286

Dev results at epoch 48:
UAR: 0.5457866957866958
ACC: 0.545822102425876
F1: 0.540986318151823
train_loss: 0.13551855610169092
val_loss: 2.2754886150360107

Dev results at epoch 49:
UAR: 0.5542383292383293
ACC: 0.5542452830188679
F1: 0.5495101566863994
train_loss: 0.13795807663583862
val_loss: 2.2240350246429443

Dev results at epoch 50:
UAR: 0.5622349622349623
ACC: 0.5623315363881402
F1: 0.5527062885291085
train_loss: 0.1392034559909634
val_loss: 2.2615294456481934

Best dev results found at epoch 41:
UAR: 0.567012467012467
ACC: 0.5670485175202157
F1: 0.5572570308547137
train_loss: 0.1863305527153601
val_loss: 2.036763906478882

Best test results:
UAR: 0.567012467012467
ACC: 0.5670485175202157
F1: 0.5572570308547137

Running experiment 6/84

Running NeuralBench with Configuration:
device:		 cuda:0
state:		 None
approach:	 cnn10
category:	 None
batch_size:	 16
epochs:		 50
learning_rate:	 0.001
seed:		 43
optimizer:	 GDTUO-Adam-Adam
exclude cities:	 None

-----------------hi---------------
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_train.csv
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_evaluate.csv
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_evaluate.csv
Dev results at epoch 1:
UAR: 0.3226533351533351
ACC: 0.3227762803234501
F1: 0.29831931044240856
train_loss: 2.0178108828447394
val_loss: 1.8136783838272095

Dev results at epoch 2:
UAR: 0.379986804986805
ACC: 0.38005390835579517
F1: 0.3607944043888615
train_loss: 1.495335764286854
val_loss: 1.6481155157089233

Dev results at epoch 3:
UAR: 0.4123168623168623
ACC: 0.4123989218328841
F1: 0.3951531751444572
train_loss: 1.4019312265948878
val_loss: 1.5687010288238525

Dev results at epoch 4:
UAR: 0.4403505778505778
ACC: 0.44036388140161725
F1: 0.42474449928306723
train_loss: 1.2954069336391942
val_loss: 1.5144485235214233

Dev results at epoch 5:
UAR: 0.42647533897533896
ACC: 0.42654986522911054
F1: 0.41415147331821994
train_loss: 1.2166652521043846
val_loss: 1.6153215169906616

Dev results at epoch 6:
UAR: 0.4540859040859041
ACC: 0.45417789757412397
F1: 0.4250171628989608
train_loss: 1.1471881150243481
val_loss: 1.5340843200683594

Dev results at epoch 7:
UAR: 0.41324278824278826
ACC: 0.4134097035040431
F1: 0.38508465376679923
train_loss: 1.097202298226089
val_loss: 1.6393502950668335

Dev results at epoch 8:
UAR: 0.47493971243971245
ACC: 0.4750673854447439
F1: 0.4395874553894782
train_loss: 1.06462691384629
val_loss: 1.4336451292037964

Dev results at epoch 9:
UAR: 0.494484256984257
ACC: 0.4946091644204852
F1: 0.47269372120779085
train_loss: 0.9888042903506332
val_loss: 1.4224863052368164

Dev results at epoch 10:
UAR: 0.5103740103740104
ACC: 0.5104447439353099
F1: 0.48568953133813386
train_loss: 0.9670763885578886
val_loss: 1.3936102390289307

Dev results at epoch 11:
UAR: 0.5093252343252344
ACC: 0.5094339622641509
F1: 0.48287437259880905
train_loss: 0.8839869611519992
val_loss: 1.3655601739883423

Dev results at epoch 12:
UAR: 0.4796808171808172
ACC: 0.4797843665768194
F1: 0.45543156542719815
train_loss: 0.8370737114244856
val_loss: 1.5159380435943604

Dev results at epoch 13:
UAR: 0.5184434434434435
ACC: 0.5185309973045822
F1: 0.5045668980709026
train_loss: 0.8042085337338443
val_loss: 1.3284084796905518

Dev results at epoch 14:
UAR: 0.528890253890254
ACC: 0.5289757412398922
F1: 0.5096160817458668
train_loss: 0.7867574948147537
val_loss: 1.320467233657837

Dev results at epoch 15:
UAR: 0.5403619528619529
ACC: 0.5404312668463612
F1: 0.532428539225212
train_loss: 0.7232943313433132
val_loss: 1.2567203044891357

Dev results at epoch 16:
UAR: 0.5242208117208117
ACC: 0.5242587601078167
F1: 0.5129472796323398
train_loss: 0.7015741307369485
val_loss: 1.3119529485702515

Dev results at epoch 17:
UAR: 0.5406770406770407
ACC: 0.5407681940700808
F1: 0.5165413229611444
train_loss: 0.6930347584094105
val_loss: 1.3291469812393188

Dev results at epoch 18:
UAR: 0.5312653562653563
ACC: 0.5313342318059299
F1: 0.522265718312514
train_loss: 0.6725490188646426
val_loss: 1.2892597913742065

Dev results at epoch 19:
UAR: 0.5295079170079171
ACC: 0.5296495956873315
F1: 0.512590881702087
train_loss: 0.6439366549048636
val_loss: 1.3146650791168213

Dev results at epoch 20:
UAR: 0.5359018109018109
ACC: 0.5360512129380054
F1: 0.5152195585653099
train_loss: 0.6371192073562574
val_loss: 1.3424761295318604

Dev results at epoch 21:
UAR: 0.5565474565474565
ACC: 0.5566037735849056
F1: 0.5519408866932689
train_loss: 0.6261110015102541
val_loss: 1.233062744140625

Dev results at epoch 22:
UAR: 0.5285990535990536
ACC: 0.5286388140161725
F1: 0.5132914947840594
train_loss: 0.6175270740621278
val_loss: 1.4064587354660034

Dev results at epoch 23:
UAR: 0.5507689507689507
ACC: 0.5508760107816711
F1: 0.5367298653615632
train_loss: 0.6209563811108009
val_loss: 1.2641339302062988

Dev results at epoch 24:
UAR: 0.5407794157794157
ACC: 0.5407681940700808
F1: 0.5191601836875844
train_loss: 0.5681652861294195
val_loss: 1.3826795816421509

Dev results at epoch 25:
UAR: 0.5619084994084995
ACC: 0.5619946091644205
F1: 0.5471689610402496
train_loss: 0.5543398254071997
val_loss: 1.2825486660003662

Dev results at epoch 26:
UAR: 0.5157100282100282
ACC: 0.5158355795148248
F1: 0.495453458353398
train_loss: 0.5593934079881796
val_loss: 1.5419535636901855

Dev results at epoch 27:
UAR: 0.482013832013832
ACC: 0.48214285714285715
F1: 0.46047812227911467
train_loss: 0.5558674623346956
val_loss: 1.5764918327331543

Dev results at epoch 28:
UAR: 0.5430464555464556
ACC: 0.5431266846361186
F1: 0.523845799529812
train_loss: 0.49919110900143165
val_loss: 1.3823996782302856

Dev results at epoch 29:
UAR: 0.5676642551642551
ACC: 0.567722371967655
F1: 0.5504238549701642
train_loss: 0.5564258979699592
val_loss: 1.2482502460479736

Dev results at epoch 30:
UAR: 0.554095004095004
ACC: 0.5542452830188679
F1: 0.5367310028936765
train_loss: 0.4983793468324453
val_loss: 1.3427919149398804

Dev results at epoch 31:
UAR: 0.5656178906178906
ACC: 0.5657008086253369
F1: 0.5542061578444542
train_loss: 0.4532150266284522
val_loss: 1.3028701543807983

Dev results at epoch 32:
UAR: 0.5709743834743835
ACC: 0.5710916442048517
F1: 0.5592482775234584
train_loss: 0.4547858989423083
val_loss: 1.3006542921066284

Dev results at epoch 33:
UAR: 0.5808171808171808
ACC: 0.5808625336927223
F1: 0.5749586340186511
train_loss: 0.46258112128486883
val_loss: 1.2541269063949585

Dev results at epoch 34:
UAR: 0.5615774865774866
ACC: 0.5616576819407008
F1: 0.5457581779405112
train_loss: 0.41643112727183795
val_loss: 1.3136924505233765

Dev results at epoch 35:
UAR: 0.5568318318318319
ACC: 0.5569407008086253
F1: 0.5397629210720487
train_loss: 0.3822675550490925
val_loss: 1.4104565382003784

Dev results at epoch 36:
UAR: 0.5788197288197288
ACC: 0.5788409703504043
F1: 0.5691363973974879
train_loss: 0.38489325476419883
val_loss: 1.3346939086914062

Dev results at epoch 37:
UAR: 0.5571901446901447
ACC: 0.557277628032345
F1: 0.5469039986774041
train_loss: 0.4102255504915463
val_loss: 1.3626312017440796

Dev results at epoch 38:
UAR: 0.5753719628719628
ACC: 0.5754716981132075
F1: 0.5676615998907579
train_loss: 0.362667257830347
val_loss: 1.305269718170166

Dev results at epoch 39:
UAR: 0.5488056238056239
ACC: 0.5488544474393531
F1: 0.5459245111277493
train_loss: 0.41082534534517434
val_loss: 1.3952157497406006

Dev results at epoch 40:
UAR: 0.5848291473291474
ACC: 0.5849056603773585
F1: 0.5756217654786365
train_loss: 0.3317696194485564
val_loss: 1.2793092727661133

Dev results at epoch 41:
UAR: 0.5821514696514696
ACC: 0.5822102425876011
F1: 0.5746144773582633
train_loss: 0.30587584442562527
val_loss: 1.3115359544754028

Dev results at epoch 42:
UAR: 0.578459140959141
ACC: 0.5785040431266847
F1: 0.570699527790375
train_loss: 0.38839946560484845
val_loss: 1.2891722917556763

Dev results at epoch 43:
UAR: 0.5828214578214579
ACC: 0.5828840970350404
F1: 0.5721293141565427
train_loss: 0.3073121812215922
val_loss: 1.3401819467544556

Dev results at epoch 44:
UAR: 0.5871712621712621
ACC: 0.5872641509433962
F1: 0.5787483749234246
train_loss: 0.30916455747369775
val_loss: 1.3348183631896973

Dev results at epoch 45:
UAR: 0.5730264355264355
ACC: 0.5731132075471698
F1: 0.5630117068812327
train_loss: 0.34110441885862974
val_loss: 1.4365251064300537

Dev results at epoch 46:
UAR: 0.5707298207298207
ACC: 0.5707547169811321
F1: 0.5654367903789626
train_loss: 0.2876635164860956
val_loss: 1.3969773054122925

Dev results at epoch 47:
UAR: 0.5568500318500318
ACC: 0.5569407008086253
F1: 0.5489702788088555
train_loss: 0.2632331066153611
val_loss: 1.4809527397155762

Dev results at epoch 48:
UAR: 0.5824824824824825
ACC: 0.5825471698113207
F1: 0.577699958787907
train_loss: 0.24999861718760324
val_loss: 1.3910176753997803

Dev results at epoch 49:
UAR: 0.5916132041132041
ACC: 0.5916442048517521
F1: 0.5875663240091471
train_loss: 0.2839631581612844
val_loss: 1.3492809534072876

Dev results at epoch 50:
UAR: 0.5764287014287015
ACC: 0.5764824797843666
F1: 0.5687623029175831
train_loss: 0.24032125143891142
val_loss: 1.4575663805007935

Best dev results found at epoch 49:
UAR: 0.5916132041132041
ACC: 0.5916442048517521
F1: 0.5875663240091471
train_loss: 0.2839631581612844
val_loss: 1.3492809534072876

Best test results:
UAR: 0.5916132041132041
ACC: 0.5916442048517521
F1: 0.5875663240091471

Running experiment 7/84

Running NeuralBench with Configuration:
device:		 cuda:0
state:		 None
approach:	 cnn10
category:	 None
batch_size:	 16
epochs:		 50
learning_rate:	 0.001
seed:		 43
optimizer:	 Adam
exclude cities:	 None

-----------------hi---------------
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_train.csv
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_evaluate.csv
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_evaluate.csv
Dev results at epoch 1:
UAR: 0.3375671125671126
ACC: 0.3376010781671159
F1: 0.312767822908092
train_loss: 2.006383829236986
val_loss: 1.7899935245513916

Dev results at epoch 2:
UAR: 0.33554463554463554
ACC: 0.33557951482479786
F1: 0.3339176340275948
train_loss: 1.5464467822754369
val_loss: 1.8136718273162842

Dev results at epoch 3:
UAR: 0.4080182455182455
ACC: 0.4080188679245283
F1: 0.39239356492637856
train_loss: 1.441806125203905
val_loss: 1.590696096420288

Dev results at epoch 4:
UAR: 0.41945581945581945
ACC: 0.4194743935309973
F1: 0.40018312913310955
train_loss: 1.3650540053366522
val_loss: 1.5572246313095093

Dev results at epoch 5:
UAR: 0.39776481026481025
ACC: 0.397911051212938
F1: 0.36691648660799264
train_loss: 1.2829457365087353
val_loss: 1.6351728439331055

Dev results at epoch 6:
UAR: 0.42848644098644095
ACC: 0.42857142857142855
F1: 0.40628723483688123
train_loss: 1.2149626611297757
val_loss: 1.6306244134902954

Dev results at epoch 7:
UAR: 0.3991354991354991
ACC: 0.3992587601078167
F1: 0.3813333056090247
train_loss: 1.157310372365709
val_loss: 1.6357609033584595

Dev results at epoch 8:
UAR: 0.45147761397761393
ACC: 0.45148247978436656
F1: 0.42793859687199165
train_loss: 1.0900057891185342
val_loss: 1.5216647386550903

Dev results at epoch 9:
UAR: 0.4820957320957321
ACC: 0.48214285714285715
F1: 0.4689374432903458
train_loss: 1.0164048791546183
val_loss: 1.4788260459899902

Dev results at epoch 10:
UAR: 0.4241832741832742
ACC: 0.4241913746630728
F1: 0.397657086479149
train_loss: 0.9841696947369243
val_loss: 1.7404381036758423

Dev results at epoch 11:
UAR: 0.48102989352989345
ACC: 0.4811320754716981
F1: 0.46180337740723615
train_loss: 0.9084587018992346
val_loss: 1.4722927808761597

Dev results at epoch 12:
UAR: 0.45613454363454364
ACC: 0.45619946091644203
F1: 0.4281511105620971
train_loss: 0.8657813363741627
val_loss: 1.5924760103225708

Dev results at epoch 13:
UAR: 0.5080842205842206
ACC: 0.5080862533692723
F1: 0.5051391164540584
train_loss: 0.8172429941022792
val_loss: 1.4671626091003418

Dev results at epoch 14:
UAR: 0.4999488124488125
ACC: 0.5
F1: 0.48527781908814316
train_loss: 0.7811998308455957
val_loss: 1.4541118144989014

Dev results at epoch 15:
UAR: 0.5208151333151333
ACC: 0.52088948787062
F1: 0.5057830350157838
train_loss: 0.729304674155114
val_loss: 1.3633188009262085

Dev results at epoch 16:
UAR: 0.5313665938665939
ACC: 0.5313342318059299
F1: 0.5238265912822504
train_loss: 0.6951500634147539
val_loss: 1.3125706911087036

Dev results at epoch 17:
UAR: 0.4945809445809445
ACC: 0.4946091644204852
F1: 0.48960222342892246
train_loss: 0.6561313014976757
val_loss: 1.5432188510894775

Dev results at epoch 18:
UAR: 0.5222517972517972
ACC: 0.5222371967654986
F1: 0.5149281154557526
train_loss: 0.6198324670616158
val_loss: 1.4189112186431885

Dev results at epoch 19:
UAR: 0.5362817362817364
ACC: 0.5363881401617251
F1: 0.5258407537193621
train_loss: 0.5883950777565218
val_loss: 1.4146884679794312

Dev results at epoch 20:
UAR: 0.5269292019292019
ACC: 0.5269541778975741
F1: 0.5174789435147626
train_loss: 0.5655712513306433
val_loss: 1.4596506357192993

Dev results at epoch 21:
UAR: 0.5545636545636545
ACC: 0.5545822102425876
F1: 0.5448769766102598
train_loss: 0.5398794438472319
val_loss: 1.4029769897460938

Dev results at epoch 22:
UAR: 0.5161741286741287
ACC: 0.5161725067385444
F1: 0.49891297411224667
train_loss: 0.5022880508940996
val_loss: 1.6433589458465576

Dev results at epoch 23:
UAR: 0.5333310583310584
ACC: 0.5333557951482479
F1: 0.533384707390108
train_loss: 0.4769254019366575
val_loss: 1.5653811693191528

Dev results at epoch 24:
UAR: 0.5306488306488306
ACC: 0.5306603773584906
F1: 0.5230288103888575
train_loss: 0.45750413695083586
val_loss: 1.610318660736084

Dev results at epoch 25:
UAR: 0.5410603785603785
ACC: 0.5411051212938005
F1: 0.5370837921726064
train_loss: 0.4357633579518104
val_loss: 1.5193772315979004

Dev results at epoch 26:
UAR: 0.5289391664391665
ACC: 0.5289757412398922
F1: 0.5168617507917831
train_loss: 0.4162082241726495
val_loss: 1.6926727294921875

Dev results at epoch 27:
UAR: 0.4841318591318592
ACC: 0.4841644204851752
F1: 0.4670988902272681
train_loss: 0.3776680590437655
val_loss: 1.9306453466415405

Dev results at epoch 28:
UAR: 0.563006188006188
ACC: 0.5630053908355795
F1: 0.561865143215851
train_loss: 0.3713852982298137
val_loss: 1.4830044507980347

Dev results at epoch 29:
UAR: 0.5326417326417326
ACC: 0.5326819407008087
F1: 0.5194009074848158
train_loss: 0.34830841446297517
val_loss: 1.6881749629974365

Dev results at epoch 30:
UAR: 0.549491536991537
ACC: 0.5495283018867925
F1: 0.5392261362092273
train_loss: 0.32003337182830016
val_loss: 1.6802196502685547

Dev results at epoch 31:
UAR: 0.5519394394394395
ACC: 0.5518867924528302
F1: 0.5473753543484634
train_loss: 0.30080013738183425
val_loss: 1.752082109451294

Dev results at epoch 32:
UAR: 0.5164585039585039
ACC: 0.5165094339622641
F1: 0.5085730765540977
train_loss: 0.28701575248494726
val_loss: 1.9910281896591187

Dev results at epoch 33:
UAR: 0.5303610428610428
ACC: 0.5303234501347709
F1: 0.519578402364796
train_loss: 0.28583831107083874
val_loss: 1.8205658197402954

Dev results at epoch 34:
UAR: 0.5464134589134588
ACC: 0.5464959568733153
F1: 0.544393113742397
train_loss: 0.2561155226239497
val_loss: 1.8069084882736206

Dev results at epoch 35:
UAR: 0.5582798707798707
ACC: 0.558288409703504
F1: 0.5553268880047629
train_loss: 0.2395333738939971
val_loss: 1.6702070236206055

Dev results at epoch 36:
UAR: 0.559622122122122
ACC: 0.5596361185983828
F1: 0.5422785901331233
train_loss: 0.23547111749051636
val_loss: 1.7366408109664917

Dev results at epoch 37:
UAR: 0.5083401583401583
ACC: 0.508423180592992
F1: 0.5027390975748093
train_loss: 0.21853986962667463
val_loss: 2.108837127685547

Dev results at epoch 38:
UAR: 0.5064041314041313
ACC: 0.5064016172506739
F1: 0.5014561992342993
train_loss: 0.22305222994990365
val_loss: 2.302638053894043

Dev results at epoch 39:
UAR: 0.5615843115843117
ACC: 0.5616576819407008
F1: 0.5627938192521064
train_loss: 0.19023483062540644
val_loss: 1.7354540824890137

Dev results at epoch 40:
UAR: 0.5438529438529438
ACC: 0.543800539083558
F1: 0.537311606432986
train_loss: 0.1855773838015032
val_loss: 1.9180577993392944

Dev results at epoch 41:
UAR: 0.5646385021385022
ACC: 0.5646900269541779
F1: 0.558775500964724
train_loss: 0.18275146914020882
val_loss: 1.8289695978164673

Dev results at epoch 42:
UAR: 0.5273273273273273
ACC: 0.5272911051212938
F1: 0.5232457172848487
train_loss: 0.18337711347517732
val_loss: 2.0875401496887207

Dev results at epoch 43:
UAR: 0.541036491036491
ACC: 0.5411051212938005
F1: 0.5335342457461079
train_loss: 0.16383079146829788
val_loss: 2.0521187782287598

Dev results at epoch 44:
UAR: 0.5215260715260714
ACC: 0.5215633423180593
F1: 0.5057703984432393
train_loss: 0.15895849278459126
val_loss: 2.427704095840454

Dev results at epoch 45:
UAR: 0.5430896805896807
ACC: 0.5431266846361186
F1: 0.5352391607264636
train_loss: 0.15405263127316374
val_loss: 2.024881362915039

Dev results at epoch 46:
UAR: 0.5027629902629902
ACC: 0.5026954177897575
F1: 0.499246850990966
train_loss: 0.14848897463102256
val_loss: 2.367790937423706

Dev results at epoch 47:
UAR: 0.5367810992810993
ACC: 0.5367250673854448
F1: 0.523492500517087
train_loss: 0.12596646614131632
val_loss: 2.1693291664123535

Dev results at epoch 48:
UAR: 0.5544828919828919
ACC: 0.5545822102425876
F1: 0.5498343062003416
train_loss: 0.1393349760335754
val_loss: 1.9415690898895264

Dev results at epoch 49:
UAR: 0.5521294021294021
ACC: 0.5522237196765498
F1: 0.5426271837095741
train_loss: 0.1400269632038894
val_loss: 2.0660669803619385

Dev results at epoch 50:
UAR: 0.561957411957412
ACC: 0.5619946091644205
F1: 0.5525391396834873
train_loss: 0.12457442534356704
val_loss: 2.108125925064087

Best dev results found at epoch 41:
UAR: 0.5646385021385022
ACC: 0.5646900269541779
F1: 0.558775500964724
train_loss: 0.18275146914020882
val_loss: 1.8289695978164673

Best test results:
UAR: 0.5646385021385022
ACC: 0.5646900269541779
F1: 0.558775500964724

Running experiment 8/84

Running NeuralBench with Configuration:
device:		 cuda:0
state:		 None
approach:	 cnn10
category:	 None
batch_size:	 16
epochs:		 50
learning_rate:	 0.001
seed:		 43
optimizer:	 SGD
exclude cities:	 None

-----------------hi---------------
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_train.csv
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_evaluate.csv
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_evaluate.csv
Dev results at epoch 1:
UAR: 0.34024024024024024
ACC: 0.34029649595687333
F1: 0.285000560480939
train_loss: 1.720750821961297
val_loss: 1.8837085962295532

Dev results at epoch 2:
UAR: 0.3606970606970607
ACC: 0.3608490566037736
F1: 0.3060932062272204
train_loss: 1.3663887892255533
val_loss: 2.139188528060913

Dev results at epoch 3:
UAR: 0.4679088179088179
ACC: 0.46799191374663074
F1: 0.4519591614385933
train_loss: 1.2216794094815424
val_loss: 1.4918450117111206

Dev results at epoch 4:
UAR: 0.49019246519246523
ACC: 0.49022911051212936
F1: 0.4720045858400921
train_loss: 1.1286776997106318
val_loss: 1.4624409675598145

Dev results at epoch 5:
UAR: 0.449446036946037
ACC: 0.4494609164420485
F1: 0.42338688352066195
train_loss: 1.0261215630743785
val_loss: 1.5852763652801514

Dev results at epoch 6:
UAR: 0.4604468104468104
ACC: 0.46057951482479786
F1: 0.41557823339039607
train_loss: 0.9521747176521559
val_loss: 1.7218061685562134

Dev results at epoch 7:
UAR: 0.46616730366730363
ACC: 0.46630727762803237
F1: 0.4466448233373696
train_loss: 0.8966331424923424
val_loss: 1.6370707750320435

Dev results at epoch 8:
UAR: 0.48317408317408306
ACC: 0.4831536388140162
F1: 0.4655787259570266
train_loss: 0.8574869731379265
val_loss: 1.5903918743133545

Dev results at epoch 9:
UAR: 0.5333367458367458
ACC: 0.5333557951482479
F1: 0.5208791328761608
train_loss: 0.8010563622362152
val_loss: 1.4175074100494385

Dev results at epoch 10:
UAR: 0.5068193193193193
ACC: 0.5067385444743935
F1: 0.4906413163830326
train_loss: 0.7730735894228584
val_loss: 1.7229176759719849

Dev results at epoch 11:
UAR: 0.5333492583492583
ACC: 0.5333557951482479
F1: 0.5142295222422839
train_loss: 0.7136452058234166
val_loss: 1.4392703771591187

Dev results at epoch 12:
UAR: 0.4702486577486578
ACC: 0.47035040431266845
F1: 0.4389605894359351
train_loss: 0.6936361457713008
val_loss: 1.9284006357192993

Dev results at epoch 13:
UAR: 0.5407839657839657
ACC: 0.5407681940700808
F1: 0.5321645603838167
train_loss: 0.6567841861631726
val_loss: 1.4739967584609985

Dev results at epoch 14:
UAR: 0.4885897260897261
ACC: 0.488544474393531
F1: 0.4655751095536324
train_loss: 0.6354885707606155
val_loss: 1.8123130798339844

Dev results at epoch 15:
UAR: 0.5484302484302483
ACC: 0.5485175202156334
F1: 0.5391181508118371
train_loss: 0.6056235591707088
val_loss: 1.4184552431106567

Dev results at epoch 16:
UAR: 0.5249055874055875
ACC: 0.5249326145552561
F1: 0.505803087064504
train_loss: 0.58082331808333
val_loss: 1.5136979818344116

Dev results at epoch 17:
UAR: 0.5377138502138503
ACC: 0.5377358490566038
F1: 0.533964202232321
train_loss: 0.5408306203500921
val_loss: 1.5187793970108032

Dev results at epoch 18:
UAR: 0.5401424151424151
ACC: 0.5400943396226415
F1: 0.5371022214195822
train_loss: 0.5264197184116434
val_loss: 1.5074381828308105

Dev results at epoch 19:
UAR: 0.5147340522340522
ACC: 0.5148247978436657
F1: 0.492402886851229
train_loss: 0.5011704961288153
val_loss: 1.6515915393829346

Dev results at epoch 20:
UAR: 0.5569023569023569
ACC: 0.5569407008086253
F1: 0.5495765902426918
train_loss: 0.4853848502091116
val_loss: 1.5422651767730713

Dev results at epoch 21:
UAR: 0.560520748020748
ACC: 0.5606469002695418
F1: 0.5483254552896566
train_loss: 0.4703975819981521
val_loss: 1.51302170753479

Dev results at epoch 22:
UAR: 0.5292917917917918
ACC: 0.5293126684636119
F1: 0.506699736051971
train_loss: 0.4368328408243184
val_loss: 1.9004048109054565

Dev results at epoch 23:
UAR: 0.5539073164073165
ACC: 0.5539083557951483
F1: 0.5526819388698532
train_loss: 0.4254510225674814
val_loss: 1.5998742580413818

Dev results at epoch 24:
UAR: 0.5293338793338793
ACC: 0.5293126684636119
F1: 0.5027291041641555
train_loss: 0.40622517415338366
val_loss: 1.8350788354873657

Dev results at epoch 25:
UAR: 0.553520566020566
ACC: 0.5535714285714286
F1: 0.5404659922215524
train_loss: 0.39239127976224597
val_loss: 1.7573354244232178

Dev results at epoch 26:
UAR: 0.5538879788879789
ACC: 0.5539083557951483
F1: 0.5510030209172277
train_loss: 0.3857638498497241
val_loss: 1.6054939031600952

Dev results at epoch 27:
UAR: 0.5211472836472837
ACC: 0.5212264150943396
F1: 0.5033738610275117
train_loss: 0.36166888360202926
val_loss: 1.9414714574813843

Dev results at epoch 28:
UAR: 0.5569728819728821
ACC: 0.5569407008086253
F1: 0.549510621112328
train_loss: 0.35240950989712966
val_loss: 1.6451187133789062

Dev results at epoch 29:
UAR: 0.5235474110474111
ACC: 0.5235849056603774
F1: 0.5100575375662543
train_loss: 0.3247281062541549
val_loss: 1.7971863746643066

Dev results at epoch 30:
UAR: 0.5592251342251341
ACC: 0.5592991913746631
F1: 0.5538014845537778
train_loss: 0.3097943385395158
val_loss: 1.607598900794983

Dev results at epoch 31:
UAR: 0.5676801801801802
ACC: 0.567722371967655
F1: 0.5644082862286223
train_loss: 0.30163348692961095
val_loss: 1.6857569217681885

Dev results at epoch 32:
UAR: 0.5329932204932205
ACC: 0.5330188679245284
F1: 0.5208220456355747
train_loss: 0.29439055931168734
val_loss: 1.8266440629959106

Dev results at epoch 33:
UAR: 0.5555544180544182
ACC: 0.5555929919137467
F1: 0.55266985648341
train_loss: 0.2783475447262617
val_loss: 1.7362940311431885

Dev results at epoch 34:
UAR: 0.5008895258895258
ACC: 0.501010781671159
F1: 0.4836127359902436
train_loss: 0.2710156050795542
val_loss: 2.3023078441619873

Dev results at epoch 35:
UAR: 0.554129129129129
ACC: 0.5542452830188679
F1: 0.5423046092573441
train_loss: 0.2453923061455921
val_loss: 1.9261106252670288

Dev results at epoch 36:
UAR: 0.5462087087087087
ACC: 0.5461590296495957
F1: 0.538209334908806
train_loss: 0.2564876823006507
val_loss: 1.8164983987808228

Dev results at epoch 37:
UAR: 0.5569114569114568
ACC: 0.5569407008086253
F1: 0.548673595813416
train_loss: 0.23187040096684386
val_loss: 1.8128999471664429

Dev results at epoch 38:
UAR: 0.545537583037583
ACC: 0.5454851752021563
F1: 0.5397053655771196
train_loss: 0.23568901745229107
val_loss: 1.9747982025146484

Dev results at epoch 39:
UAR: 0.5683638183638184
ACC: 0.5683962264150944
F1: 0.5649124714019438
train_loss: 0.2239359619169531
val_loss: 1.7441350221633911

Dev results at epoch 40:
UAR: 0.5677393302393303
ACC: 0.567722371967655
F1: 0.5564509281457504
train_loss: 0.19957111096105626
val_loss: 1.8271576166152954

Dev results at epoch 41:
UAR: 0.5817578942578943
ACC: 0.5818733153638814
F1: 0.575686099223323
train_loss: 0.2071782320648227
val_loss: 1.6879093647003174

Dev results at epoch 42:
UAR: 0.5667121667121667
ACC: 0.566711590296496
F1: 0.5634870595493622
train_loss: 0.21253635860416284
val_loss: 1.7418767213821411

Dev results at epoch 43:
UAR: 0.5555305305305305
ACC: 0.5555929919137467
F1: 0.5547089798166727
train_loss: 0.18452473292457963
val_loss: 1.9338200092315674

Dev results at epoch 44:
UAR: 0.5444205569205569
ACC: 0.5444743935309974
F1: 0.5307513197366994
train_loss: 0.18519514326202466
val_loss: 2.100612163543701

Dev results at epoch 45:
UAR: 0.5346482846482846
ACC: 0.5347035040431267
F1: 0.5232051765275617
train_loss: 0.17954729039959166
val_loss: 2.146824359893799

Dev results at epoch 46:
UAR: 0.5410319410319411
ACC: 0.5411051212938005
F1: 0.5360907951198712
train_loss: 0.17329489465649286
val_loss: 2.032370090484619

Dev results at epoch 47:
UAR: 0.543515106015106
ACC: 0.5434636118598383
F1: 0.5316766298408571
train_loss: 0.15775563232632694
val_loss: 2.1569783687591553

Dev results at epoch 48:
UAR: 0.5683820183820184
ACC: 0.5683962264150944
F1: 0.5596580008532094
train_loss: 0.15270338668023906
val_loss: 1.8871335983276367

Dev results at epoch 49:
UAR: 0.5491718991718992
ACC: 0.5491913746630728
F1: 0.5399340735846281
train_loss: 0.1594704620234502
val_loss: 2.057662010192871

Dev results at epoch 50:
UAR: 0.5457696332696333
ACC: 0.545822102425876
F1: 0.5328118460488899
train_loss: 0.14213648484966462
val_loss: 2.26119065284729

Best dev results found at epoch 41:
UAR: 0.5817578942578943
ACC: 0.5818733153638814
F1: 0.575686099223323
train_loss: 0.2071782320648227
val_loss: 1.6879093647003174

Best test results:
UAR: 0.5817578942578943
ACC: 0.5818733153638814
F1: 0.575686099223323

Running experiment 9/84

Running NeuralBench with Configuration:
device:		 cuda:0
state:		 None
approach:	 cnn10
category:	 None
batch_size:	 16
epochs:		 50
learning_rate:	 0.001
seed:		 44
optimizer:	 KFACOptimizer
exclude cities:	 None

-----------------hi---------------
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_train.csv
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_evaluate.csv
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_evaluate.csv
Dev results at epoch 1:
UAR: 0.3311470561470561
ACC: 0.33119946091644203
F1: 0.3184166893059326
train_loss: 2.632250058009179
val_loss: 1.7623265981674194

Dev results at epoch 2:
UAR: 0.3577532077532078
ACC: 0.3578167115902965
F1: 0.335324824104327
train_loss: 1.5718765759932354
val_loss: 1.6705305576324463

Dev results at epoch 3:
UAR: 0.4015083265083265
ACC: 0.40161725067385445
F1: 0.38579769917587126
train_loss: 1.4000379790691713
val_loss: 1.7392168045043945

Dev results at epoch 4:
UAR: 0.42886522886522893
ACC: 0.42890835579514824
F1: 0.414943815909964
train_loss: 1.251949434427871
val_loss: 1.5112521648406982

Dev results at epoch 5:
UAR: 0.43622599872599876
ACC: 0.4363207547169811
F1: 0.4104734527686813
train_loss: 1.1393223611759566
val_loss: 1.580714464187622

Dev results at epoch 6:
UAR: 0.45691941941941944
ACC: 0.4568733153638814
F1: 0.4463930316826554
train_loss: 1.0417432737582601
val_loss: 1.4629404544830322

Dev results at epoch 7:
UAR: 0.47500568750568756
ACC: 0.4750673854447439
F1: 0.4509941044193916
train_loss: 0.9589861605448685
val_loss: 1.4992789030075073

Dev results at epoch 8:
UAR: 0.4733221858221858
ACC: 0.47338274932614555
F1: 0.4576390438374613
train_loss: 0.8880298837831613
val_loss: 1.5547579526901245

Dev results at epoch 9:
UAR: 0.47705660205660205
ACC: 0.477088948787062
F1: 0.46352843194386306
train_loss: 0.8354737402408257
val_loss: 1.5634249448776245

Dev results at epoch 10:
UAR: 0.5191828191828193
ACC: 0.5192048517520216
F1: 0.50898647505813
train_loss: 0.7746683594867809
val_loss: 1.3883098363876343

Dev results at epoch 11:
UAR: 0.5127548002548001
ACC: 0.5128032345013477
F1: 0.4961165902055459
train_loss: 0.7364015690512946
val_loss: 1.4523882865905762

Dev results at epoch 12:
UAR: 0.5212246337246338
ACC: 0.5212264150943396
F1: 0.518053355610298
train_loss: 0.6812141131255498
val_loss: 1.4146702289581299

Dev results at epoch 13:
UAR: 0.5511773136773137
ACC: 0.5512129380053908
F1: 0.5494541589949119
train_loss: 0.6253216210816734
val_loss: 1.3816633224487305

Dev results at epoch 14:
UAR: 0.5164118664118664
ACC: 0.5165094339622641
F1: 0.5124789672528203
train_loss: 0.5962265618358827
val_loss: 1.5916101932525635

Dev results at epoch 15:
UAR: 0.5225998725998726
ACC: 0.5225741239892183
F1: 0.5193882540430851
train_loss: 0.5510936038395793
val_loss: 1.5159449577331543

Dev results at epoch 16:
UAR: 0.5178769678769679
ACC: 0.5178571428571429
F1: 0.5058737754687624
train_loss: 0.527996893515565
val_loss: 1.6166423559188843

Dev results at epoch 17:
UAR: 0.5261727636727637
ACC: 0.5262803234501348
F1: 0.5235798837152477
train_loss: 0.48449074059622393
val_loss: 1.6074174642562866

Dev results at epoch 18:
UAR: 0.5224792974792976
ACC: 0.5225741239892183
F1: 0.5219875498672766
train_loss: 0.4495823749118108
val_loss: 1.6945983171463013

Dev results at epoch 19:
UAR: 0.5390708890708891
ACC: 0.5390835579514824
F1: 0.5356850640570064
train_loss: 0.4228530092226749
val_loss: 1.64143705368042

Dev results at epoch 20:
UAR: 0.5279631904631905
ACC: 0.5279649595687331
F1: 0.5225462667181189
train_loss: 0.4024957274124112
val_loss: 1.7781181335449219

Dev results at epoch 21:
UAR: 0.5465010465010465
ACC: 0.5464959568733153
F1: 0.5391953489401515
train_loss: 0.38581929096412276
val_loss: 1.6612865924835205

Dev results at epoch 22:
UAR: 0.5278881153881154
ACC: 0.5279649595687331
F1: 0.5281904612328467
train_loss: 0.3393068584524957
val_loss: 1.7478188276290894

Dev results at epoch 23:
UAR: 0.5397181272181273
ACC: 0.5397574123989218
F1: 0.5343438517565997
train_loss: 0.3355769894138098
val_loss: 1.7977827787399292

Dev results at epoch 24:
UAR: 0.5339623714623715
ACC: 0.5340296495956873
F1: 0.5281542455191575
train_loss: 0.3062502902688166
val_loss: 1.9010727405548096

Dev results at epoch 25:
UAR: 0.5242208117208118
ACC: 0.5242587601078167
F1: 0.5174087520153517
train_loss: 0.3068283973720441
val_loss: 1.9739863872528076

Dev results at epoch 26:
UAR: 0.5309821184821184
ACC: 0.5309973045822103
F1: 0.5299019066033257
train_loss: 0.3010372509923844
val_loss: 1.8872894048690796

Dev results at epoch 27:
UAR: 0.5382860132860132
ACC: 0.5384097035040432
F1: 0.5367176004810081
train_loss: 0.2618150496087277
val_loss: 2.0300793647766113

Dev results at epoch 28:
UAR: 0.5586131586131586
ACC: 0.5586253369272237
F1: 0.5561354704424962
train_loss: 0.24853159334800737
val_loss: 1.8631864786148071

Dev results at epoch 29:
UAR: 0.5457764582764584
ACC: 0.545822102425876
F1: 0.5366236175691688
train_loss: 0.24885790494141538
val_loss: 2.1237409114837646

Dev results at epoch 30:
UAR: 0.5269860769860769
ACC: 0.5269541778975741
F1: 0.521257356686037
train_loss: 0.23899202459605937
val_loss: 2.0638604164123535

Dev results at epoch 31:
UAR: 0.5572197197197197
ACC: 0.557277628032345
F1: 0.5593167348269346
train_loss: 0.23320073704021893
val_loss: 1.9282054901123047

Dev results at epoch 32:
UAR: 0.5491480116480116
ACC: 0.5491913746630728
F1: 0.5388431158185794
train_loss: 0.22443584919739665
val_loss: 2.08150053024292

Dev results at epoch 33:
UAR: 0.5468240968240968
ACC: 0.546832884097035
F1: 0.5419282737864151
train_loss: 0.18000153305925395
val_loss: 2.0419068336486816

Dev results at epoch 34:
UAR: 0.5415051415051415
ACC: 0.5414420485175202
F1: 0.5302977652072579
train_loss: 0.20324927180491276
val_loss: 2.2498624324798584

Dev results at epoch 35:
UAR: 0.5488363363363364
ACC: 0.5488544474393531
F1: 0.5424572650833928
train_loss: 0.19966460773529313
val_loss: 2.207578659057617

Dev results at epoch 36:
UAR: 0.5380880880880881
ACC: 0.5380727762803235
F1: 0.5325382979986194
train_loss: 0.19196764371071953
val_loss: 2.2552430629730225

Dev results at epoch 37:
UAR: 0.5605935480935481
ACC: 0.5606469002695418
F1: 0.5608633084509215
train_loss: 0.18034296372253555
val_loss: 1.931614637374878

Dev results at epoch 38:
UAR: 0.5750853125853126
ACC: 0.5751347708894878
F1: 0.5674628178769154
train_loss: 0.18644090817936132
val_loss: 2.0107107162475586

Dev results at epoch 39:
UAR: 0.5236145236145237
ACC: 0.5235849056603774
F1: 0.5130864986959572
train_loss: 0.16760361679227712
val_loss: 2.375577926635742

Dev results at epoch 40:
UAR: 0.5511739011739011
ACC: 0.5512129380053908
F1: 0.5355227118233221
train_loss: 0.17675002113721822
val_loss: 2.210406541824341

Dev results at epoch 41:
UAR: 0.543444580944581
ACC: 0.5434636118598383
F1: 0.5389970391271256
train_loss: 0.16098841661368662
val_loss: 2.3511154651641846

Dev results at epoch 42:
UAR: 0.5791609791609791
ACC: 0.579177897574124
F1: 0.5765705959958118
train_loss: 0.17275017075194474
val_loss: 1.9897674322128296

Dev results at epoch 43:
UAR: 0.5390162890162891
ACC: 0.5390835579514824
F1: 0.5352961971028483
train_loss: 0.16119449633455815
val_loss: 2.4391191005706787

Dev results at epoch 44:
UAR: 0.5603205478205477
ACC: 0.5603099730458221
F1: 0.5594425648546408
train_loss: 0.15892739620052795
val_loss: 2.1862239837646484

Dev results at epoch 45:
UAR: 0.5616286741286742
ACC: 0.5616576819407008
F1: 0.555618532363865
train_loss: 0.12843312063712609
val_loss: 2.171422004699707

Dev results at epoch 46:
UAR: 0.5407646282646283
ACC: 0.5407681940700808
F1: 0.5333759904539519
train_loss: 0.12433865139540125
val_loss: 2.5117087364196777

Dev results at epoch 47:
UAR: 0.5417519792519794
ACC: 0.5417789757412399
F1: 0.5408928246583848
train_loss: 0.13478951996489974
val_loss: 2.417587995529175

Dev results at epoch 48:
UAR: 0.5646362271362271
ACC: 0.5646900269541779
F1: 0.5565739353398783
train_loss: 0.13091354015993248
val_loss: 2.368558645248413

Dev results at epoch 49:
UAR: 0.5605673855673856
ACC: 0.5606469002695418
F1: 0.5508627236797639
train_loss: 0.12142536559318595
val_loss: 2.404149293899536

Dev results at epoch 50:
UAR: 0.54244812994813
ACC: 0.5424528301886793
F1: 0.5396829231191139
train_loss: 0.137869522588998
val_loss: 2.464221954345703

Best dev results found at epoch 42:
UAR: 0.5791609791609791
ACC: 0.579177897574124
F1: 0.5765705959958118
train_loss: 0.17275017075194474
val_loss: 1.9897674322128296

Best test results:
UAR: 0.5791609791609791
ACC: 0.579177897574124
F1: 0.5765705959958118

Running experiment 10/84

Running NeuralBench with Configuration:
device:		 cuda:0
state:		 None
approach:	 cnn10
category:	 None
batch_size:	 16
epochs:		 50
learning_rate:	 0.001
seed:		 44
optimizer:	 GDTUO-Adam-Adam
exclude cities:	 None

-----------------hi---------------
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_train.csv
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_evaluate.csv
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_evaluate.csv
Dev results at epoch 1:
UAR: 0.34506552006552005
ACC: 0.3450134770889488
F1: 0.3151023631271721
train_loss: 2.0202371036337277
val_loss: 1.7612113952636719

Dev results at epoch 2:
UAR: 0.40739261989261993
ACC: 0.40734501347708896
F1: 0.389526426479907
train_loss: 1.4746653351587118
val_loss: 1.6150091886520386

Dev results at epoch 3:
UAR: 0.4055407680407681
ACC: 0.4056603773584906
F1: 0.37359525132723836
train_loss: 1.344699555246281
val_loss: 1.6247475147247314

Dev results at epoch 4:
UAR: 0.47833401583401586
ACC: 0.4784366576819407
F1: 0.4520993335736548
train_loss: 1.2390159890823758
val_loss: 1.4382508993148804

Dev results at epoch 5:
UAR: 0.4935776685776686
ACC: 0.49359838274932616
F1: 0.470969520539983
train_loss: 1.1413129501872592
val_loss: 1.3865638971328735

Dev results at epoch 6:
UAR: 0.48975793975793974
ACC: 0.4898921832884097
F1: 0.4732145504328111
train_loss: 1.0851310533210037
val_loss: 1.3813374042510986

Dev results at epoch 7:
UAR: 0.5046626171626172
ACC: 0.5047169811320755
F1: 0.485655457431987
train_loss: 1.0203290333862567
val_loss: 1.3258681297302246

Dev results at epoch 8:
UAR: 0.520480707980708
ACC: 0.5205525606469003
F1: 0.5045974102819794
train_loss: 1.0005806588908104
val_loss: 1.2989879846572876

Dev results at epoch 9:
UAR: 0.4985997360997361
ACC: 0.49865229110512127
F1: 0.48080421270012585
train_loss: 0.9580643488028069
val_loss: 1.3816919326782227

Dev results at epoch 10:
UAR: 0.5279313404313405
ACC: 0.5279649595687331
F1: 0.5143535287156249
train_loss: 0.9927736984358894
val_loss: 1.2438740730285645

Dev results at epoch 11:
UAR: 0.5275161525161526
ACC: 0.5276280323450134
F1: 0.5074149001529396
train_loss: 0.9037034972768195
val_loss: 1.2879287004470825

Dev results at epoch 12:
UAR: 0.5309206934206934
ACC: 0.5309973045822103
F1: 0.5184278764972953
train_loss: 0.8583759489338013
val_loss: 1.2833809852600098

Dev results at epoch 13:
UAR: 0.5375784875784877
ACC: 0.5377358490566038
F1: 0.5330927765286433
train_loss: 0.8287749094856564
val_loss: 1.2856348752975464

Dev results at epoch 14:
UAR: 0.5285126035126035
ACC: 0.5286388140161725
F1: 0.5082644327588082
train_loss: 0.8021494974931628
val_loss: 1.3027085065841675

Dev results at epoch 15:
UAR: 0.5512091637091637
ACC: 0.5512129380053908
F1: 0.5452699076934665
train_loss: 0.7781222300499439
val_loss: 1.2470226287841797

Dev results at epoch 16:
UAR: 0.5373430248430249
ACC: 0.5373989218328841
F1: 0.52922040544894
train_loss: 0.7445222412461131
val_loss: 1.3154953718185425

Dev results at epoch 17:
UAR: 0.5635681135681134
ACC: 0.5636792452830188
F1: 0.5581139221098307
train_loss: 0.710287662374468
val_loss: 1.2029905319213867

Dev results at epoch 18:
UAR: 0.5502047502047501
ACC: 0.5502021563342318
F1: 0.5480346414939905
train_loss: 0.712470865638805
val_loss: 1.2780147790908813

Dev results at epoch 19:
UAR: 0.5662821912821914
ACC: 0.5663746630727763
F1: 0.5542998584056809
train_loss: 0.6927663155779124
val_loss: 1.2439906597137451

Dev results at epoch 20:
UAR: 0.5545443170443171
ACC: 0.5545822102425876
F1: 0.549059875344224
train_loss: 0.6603720086751524
val_loss: 1.2953513860702515

Dev results at epoch 21:
UAR: 0.5751205751205751
ACC: 0.5751347708894878
F1: 0.5680996212773148
train_loss: 0.6432661445553224
val_loss: 1.2089794874191284

Dev results at epoch 22:
UAR: 0.5655428155428156
ACC: 0.5657008086253369
F1: 0.5506599828193826
train_loss: 0.6682870371815538
val_loss: 1.2138638496398926

Dev results at epoch 23:
UAR: 0.5804702429702431
ACC: 0.5805256064690026
F1: 0.5806742591608047
train_loss: 0.6159060824948351
val_loss: 1.1869921684265137

Dev results at epoch 24:
UAR: 0.5669180544180544
ACC: 0.5670485175202157
F1: 0.5486467069159726
train_loss: 0.6081900629561655
val_loss: 1.3042187690734863

Dev results at epoch 25:
UAR: 0.5376524251524251
ACC: 0.5377358490566038
F1: 0.5230408796368267
train_loss: 0.599426673296391
val_loss: 1.3225669860839844

Dev results at epoch 26:
UAR: 0.5743959868959869
ACC: 0.5744609164420486
F1: 0.568353044084241
train_loss: 0.5870011820279719
val_loss: 1.195420265197754

Dev results at epoch 27:
UAR: 0.5831615706615707
ACC: 0.5832210242587601
F1: 0.5796611940325643
train_loss: 0.5431887526214464
val_loss: 1.1868396997451782

Dev results at epoch 28:
UAR: 0.5532612157612158
ACC: 0.5532345013477089
F1: 0.5495707601980684
train_loss: 0.5155630014316186
val_loss: 1.2956030368804932

Dev results at epoch 29:
UAR: 0.5872406497406498
ACC: 0.5872641509433962
F1: 0.5790616492564784
train_loss: 0.5090743063310031
val_loss: 1.2095640897750854

Dev results at epoch 30:
UAR: 0.5573255073255075
ACC: 0.557277628032345
F1: 0.5528448300852012
train_loss: 0.48965534077955136
val_loss: 1.249731183052063

Dev results at epoch 31:
UAR: 0.5625898625898627
ACC: 0.5626684636118598
F1: 0.5577009716740676
train_loss: 0.5103119128177802
val_loss: 1.2823033332824707

Dev results at epoch 32:
UAR: 0.5639423514423514
ACC: 0.5640161725067385
F1: 0.5544896457779274
train_loss: 0.5159024397190767
val_loss: 1.291782259941101

Dev results at epoch 33:
UAR: 0.5673503048503049
ACC: 0.5673854447439353
F1: 0.5599908215156342
train_loss: 0.44458833159313443
val_loss: 1.3318902254104614

Dev results at epoch 34:
UAR: 0.5676972426972426
ACC: 0.567722371967655
F1: 0.553642569078803
train_loss: 0.4802629353152108
val_loss: 1.3482890129089355

Dev results at epoch 35:
UAR: 0.5717137592137591
ACC: 0.5717654986522911
F1: 0.5682219216031447
train_loss: 0.45700502486095124
val_loss: 1.2663270235061646

Dev results at epoch 36:
UAR: 0.5696719446719446
ACC: 0.569743935309973
F1: 0.5628456842691375
train_loss: 0.46599767813704407
val_loss: 1.2975878715515137

Dev results at epoch 37:
UAR: 0.5993129493129492
ACC: 0.5993935309973046
F1: 0.5925340112425472
train_loss: 0.43191948463075625
val_loss: 1.2323977947235107

Dev results at epoch 38:
UAR: 0.5572288197288197
ACC: 0.557277628032345
F1: 0.5537153533128205
train_loss: 0.4358341842889786
val_loss: 1.390208125114441

Dev results at epoch 39:
UAR: 0.5835756210756211
ACC: 0.5835579514824798
F1: 0.5784244581823608
train_loss: 0.4097506972659221
val_loss: 1.276374340057373

Dev results at epoch 40:
UAR: 0.5861895986895987
ACC: 0.5862533692722371
F1: 0.5826716227211094
train_loss: 0.36840689620099115
val_loss: 1.3422625064849854

Dev results at epoch 41:
UAR: 0.5595675220675221
ACC: 0.5596361185983828
F1: 0.5509174778373922
train_loss: 0.40529496483035377
val_loss: 1.4666093587875366

Dev results at epoch 42:
UAR: 0.5838224588224589
ACC: 0.5838948787061995
F1: 0.5815885125990949
train_loss: 0.3758566185985644
val_loss: 1.2847850322723389

Dev results at epoch 43:
UAR: 0.5959834834834835
ACC: 0.5960242587601078
F1: 0.5949164419081499
train_loss: 0.33222981347763253
val_loss: 1.3089892864227295

Dev results at epoch 44:
UAR: 0.5987294112294113
ACC: 0.5987196765498652
F1: 0.5958632287825006
train_loss: 0.3454335643936542
val_loss: 1.2661672830581665

Dev results at epoch 45:
UAR: 0.5859120484120484
ACC: 0.5859164420485176
F1: 0.5826753564412468
train_loss: 0.31832706946602257
val_loss: 1.3515065908432007

Dev results at epoch 46:
UAR: 0.5659875784875783
ACC: 0.5660377358490566
F1: 0.5596647868004662
train_loss: 0.3103203851674157
val_loss: 1.4260945320129395

Dev results at epoch 47:
UAR: 0.5757154882154882
ACC: 0.5758086253369272
F1: 0.5712826389569419
train_loss: 0.3146071037211437
val_loss: 1.4207078218460083

Dev results at epoch 48:
UAR: 0.6043782418782419
ACC: 0.6044474393530997
F1: 0.6012614447662028
train_loss: 0.32492013098106626
val_loss: 1.3096363544464111

Dev results at epoch 49:
UAR: 0.5844947219947221
ACC: 0.5845687331536388
F1: 0.5779069207125477
train_loss: 0.2991554902787539
val_loss: 1.3955376148223877

Dev results at epoch 50:
UAR: 0.5922422422422422
ACC: 0.5923180592991913
F1: 0.5882459735355805
train_loss: 0.3028583868544331
val_loss: 1.396716833114624

Best dev results found at epoch 48:
UAR: 0.6043782418782419
ACC: 0.6044474393530997
F1: 0.6012614447662028
train_loss: 0.32492013098106626
val_loss: 1.3096363544464111

Best test results:
UAR: 0.6043782418782419
ACC: 0.6044474393530997
F1: 0.6012614447662028

Running experiment 11/84

Running NeuralBench with Configuration:
device:		 cuda:0
state:		 None
approach:	 cnn10
category:	 None
batch_size:	 16
epochs:		 50
learning_rate:	 0.001
seed:		 44
optimizer:	 Adam
exclude cities:	 None

-----------------hi---------------
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_train.csv
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_evaluate.csv
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_evaluate.csv
Dev results at epoch 1:
UAR: 0.3494164619164619
ACC: 0.3493935309973046
F1: 0.3246053803953898
train_loss: 1.9583320426503954
val_loss: 1.7512189149856567

Dev results at epoch 2:
UAR: 0.33911411411411413
ACC: 0.3389487870619946
F1: 0.31159186064149447
train_loss: 1.5485750228542097
val_loss: 1.715659260749817

Dev results at epoch 3:
UAR: 0.35810469560469554
ACC: 0.3581536388140162
F1: 0.3239032412326329
train_loss: 1.446021141328626
val_loss: 1.7913172245025635

Dev results at epoch 4:
UAR: 0.40183023933023937
ACC: 0.40195417789757415
F1: 0.37009756207552813
train_loss: 1.3389574401976727
val_loss: 1.6337658166885376

Dev results at epoch 5:
UAR: 0.4497451997451997
ACC: 0.4497978436657682
F1: 0.43036477254931693
train_loss: 1.2762005274511559
val_loss: 1.5073333978652954

Dev results at epoch 6:
UAR: 0.4335289835289835
ACC: 0.4336253369272237
F1: 0.4247376437885362
train_loss: 1.1903280123539124
val_loss: 1.5146498680114746

Dev results at epoch 7:
UAR: 0.48785717535717543
ACC: 0.48787061994609165
F1: 0.4632874108542445
train_loss: 1.117236017224988
val_loss: 1.406865119934082

Dev results at epoch 8:
UAR: 0.4463406588406588
ACC: 0.44642857142857145
F1: 0.4365822282202519
train_loss: 1.06090987124667
val_loss: 1.4845075607299805

Dev results at epoch 9:
UAR: 0.45618573118573125
ACC: 0.45619946091644203
F1: 0.4339069338879108
train_loss: 1.0086286112000442
val_loss: 1.64306640625

Dev results at epoch 10:
UAR: 0.5329590954590955
ACC: 0.5330188679245284
F1: 0.5226742254596651
train_loss: 0.9474317840762427
val_loss: 1.2881773710250854

Dev results at epoch 11:
UAR: 0.5117219492219494
ACC: 0.5117924528301887
F1: 0.49176126403408044
train_loss: 0.8994412538590164
val_loss: 1.3767048120498657

Dev results at epoch 12:
UAR: 0.506428018928019
ACC: 0.5064016172506739
F1: 0.4935153513437614
train_loss: 0.861161032254207
val_loss: 1.3817723989486694

Dev results at epoch 13:
UAR: 0.5323118573118573
ACC: 0.532345013477089
F1: 0.5342992149539618
train_loss: 0.8064454210173223
val_loss: 1.288854718208313

Dev results at epoch 14:
UAR: 0.5545192920192921
ACC: 0.5545822102425876
F1: 0.5419386473465364
train_loss: 0.7694177381088371
val_loss: 1.2620586156845093

Dev results at epoch 15:
UAR: 0.5010988260988262
ACC: 0.501010781671159
F1: 0.49725709633897586
train_loss: 0.7264174874466582
val_loss: 1.3633486032485962

Dev results at epoch 16:
UAR: 0.5087769587769587
ACC: 0.5087601078167115
F1: 0.474231853081275
train_loss: 0.7009784530289258
val_loss: 1.6379806995391846

Dev results at epoch 17:
UAR: 0.48165210665210667
ACC: 0.48180592991913745
F1: 0.45297958466069765
train_loss: 0.6664680946631121
val_loss: 1.747739553451538

Dev results at epoch 18:
UAR: 0.5048571298571298
ACC: 0.5047169811320755
F1: 0.49539487362688517
train_loss: 0.6249953311060439
val_loss: 1.5536184310913086

Dev results at epoch 19:
UAR: 0.5579716079716079
ACC: 0.5579514824797843
F1: 0.5514925527647769
train_loss: 0.6019662119371375
val_loss: 1.3455404043197632

Dev results at epoch 20:
UAR: 0.5401105651105651
ACC: 0.5400943396226415
F1: 0.53695308847918
train_loss: 0.5699166883069079
val_loss: 1.3867608308792114

Dev results at epoch 21:
UAR: 0.5421216671216672
ACC: 0.5421159029649596
F1: 0.5266973302965191
train_loss: 0.5366259606177455
val_loss: 1.5698100328445435

Dev results at epoch 22:
UAR: 0.5672661297661298
ACC: 0.5673854447439353
F1: 0.5562423340433307
train_loss: 0.5144952054968678
val_loss: 1.3716682195663452

Dev results at epoch 23:
UAR: 0.5511955136955138
ACC: 0.5512129380053908
F1: 0.550157242058172
train_loss: 0.4925007504994585
val_loss: 1.3767286539077759

Dev results at epoch 24:
UAR: 0.5238215488215487
ACC: 0.523921832884097
F1: 0.5101390178276025
train_loss: 0.4531000656292338
val_loss: 1.614081621170044

Dev results at epoch 25:
UAR: 0.5525218400218399
ACC: 0.5525606469002695
F1: 0.5437179391051049
train_loss: 0.4422682933637367
val_loss: 1.5280874967575073

Dev results at epoch 26:
UAR: 0.5377752752752752
ACC: 0.5377358490566038
F1: 0.5225167283872919
train_loss: 0.428836168164445
val_loss: 1.6159650087356567

Dev results at epoch 27:
UAR: 0.5726829101829103
ACC: 0.5727762803234502
F1: 0.5683751237813873
train_loss: 0.39643287338649286
val_loss: 1.41219162940979

Dev results at epoch 28:
UAR: 0.5509338884338885
ACC: 0.5508760107816711
F1: 0.5473878044521148
train_loss: 0.3741944883453989
val_loss: 1.6758077144622803

Dev results at epoch 29:
UAR: 0.5431249431249432
ACC: 0.5431266846361186
F1: 0.536772637288865
train_loss: 0.3615674585027179
val_loss: 1.631543755531311

Dev results at epoch 30:
UAR: 0.5502877877877878
ACC: 0.5502021563342318
F1: 0.5382936089858973
train_loss: 0.35102543149267207
val_loss: 1.5843578577041626

Dev results at epoch 31:
UAR: 0.5495529620529621
ACC: 0.5495283018867925
F1: 0.5495171964269523
train_loss: 0.3157087473597757
val_loss: 1.5433852672576904

Dev results at epoch 32:
UAR: 0.5852386477386478
ACC: 0.5852425876010782
F1: 0.5809105544066215
train_loss: 0.30308853777473255
val_loss: 1.5879307985305786

Dev results at epoch 33:
UAR: 0.583543771043771
ACC: 0.5835579514824798
F1: 0.580490527086421
train_loss: 0.28368716377376624
val_loss: 1.5743334293365479

Dev results at epoch 34:
UAR: 0.5630187005187006
ACC: 0.5630053908355795
F1: 0.5513317132176334
train_loss: 0.28561635386787637
val_loss: 1.7130134105682373

Dev results at epoch 35:
UAR: 0.5845515970515971
ACC: 0.5845687331536388
F1: 0.5779896554241517
train_loss: 0.2454547881749368
val_loss: 1.6907745599746704

Dev results at epoch 36:
UAR: 0.5626694876694877
ACC: 0.5626684636118598
F1: 0.554694247695318
train_loss: 0.2545854562919113
val_loss: 1.7032052278518677

Dev results at epoch 37:
UAR: 0.5646146146146147
ACC: 0.5646900269541779
F1: 0.5599747262934178
train_loss: 0.24109579301423223
val_loss: 1.6823190450668335

Dev results at epoch 38:
UAR: 0.5448357448357448
ACC: 0.5448113207547169
F1: 0.5365676781398806
train_loss: 0.22074386615301872
val_loss: 2.0741708278656006

Dev results at epoch 39:
UAR: 0.5640663390663392
ACC: 0.5640161725067385
F1: 0.5609795642269034
train_loss: 0.22749794938122558
val_loss: 1.7872332334518433

Dev results at epoch 40:
UAR: 0.5741207116207117
ACC: 0.5741239892183289
F1: 0.5665256985841822
train_loss: 0.2020730337449152
val_loss: 1.8726472854614258

Dev results at epoch 41:
UAR: 0.5730764855764855
ACC: 0.5731132075471698
F1: 0.5691219997981666
train_loss: 0.20333284881064095
val_loss: 1.773910641670227

Dev results at epoch 42:
UAR: 0.5717251342251342
ACC: 0.5717654986522911
F1: 0.5629010005941192
train_loss: 0.17592398552672098
val_loss: 1.8088704347610474

Dev results at epoch 43:
UAR: 0.5771567021567022
ACC: 0.5771563342318059
F1: 0.570496789423667
train_loss: 0.1785088356516035
val_loss: 1.842368245124817

Dev results at epoch 44:
UAR: 0.5635954135954135
ACC: 0.5636792452830188
F1: 0.559188016785181
train_loss: 0.17163999656637766
val_loss: 1.813831090927124

Dev results at epoch 45:
UAR: 0.563017563017563
ACC: 0.5630053908355795
F1: 0.5553500713420445
train_loss: 0.1540630552050938
val_loss: 1.9089900255203247

Dev results at epoch 46:
UAR: 0.5303644553644554
ACC: 0.5303234501347709
F1: 0.5154807850219292
train_loss: 0.1546544929849515
val_loss: 2.3998727798461914

Dev results at epoch 47:
UAR: 0.5717831467831468
ACC: 0.5717654986522911
F1: 0.5644407262829529
train_loss: 0.15358195125238963
val_loss: 2.043123483657837

Dev results at epoch 48:
UAR: 0.5704283829283829
ACC: 0.5704177897574124
F1: 0.5651130348643836
train_loss: 0.13717148164892623
val_loss: 1.8837486505508423

Dev results at epoch 49:
UAR: 0.5551255801255801
ACC: 0.555256064690027
F1: 0.5395942754163007
train_loss: 0.11954880232124228
val_loss: 2.3061392307281494

Dev results at epoch 50:
UAR: 0.5734529984529984
ACC: 0.5734501347708895
F1: 0.5733125680649389
train_loss: 0.1283875870906971
val_loss: 2.0253708362579346

Best dev results found at epoch 32:
UAR: 0.5852386477386478
ACC: 0.5852425876010782
F1: 0.5809105544066215
train_loss: 0.30308853777473255
val_loss: 1.5879307985305786

Best test results:
UAR: 0.5852386477386478
ACC: 0.5852425876010782
F1: 0.5809105544066215

Running experiment 12/84

Running NeuralBench with Configuration:
device:		 cuda:0
state:		 None
approach:	 cnn10
category:	 None
batch_size:	 16
epochs:		 50
learning_rate:	 0.001
seed:		 44
optimizer:	 SGD
exclude cities:	 None

-----------------hi---------------
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_train.csv
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_evaluate.csv
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_evaluate.csv
Dev results at epoch 1:
UAR: 0.4021794521794521
ACC: 0.4022911051212938
F1: 0.3671697838299709
train_loss: 1.7413123583875572
val_loss: 1.688855767250061

Dev results at epoch 2:
UAR: 0.44937892437892435
ACC: 0.4494609164420485
F1: 0.41462377908294473
train_loss: 1.3507789658790055
val_loss: 1.5197380781173706

Dev results at epoch 3:
UAR: 0.4297558922558922
ACC: 0.4299191374663073
F1: 0.40262201627206096
train_loss: 1.211642378589132
val_loss: 1.8915343284606934

Dev results at epoch 4:
UAR: 0.4827054327054328
ACC: 0.4828167115902965
F1: 0.46458950461722237
train_loss: 1.0970191310702866
val_loss: 1.4361947774887085

Dev results at epoch 5:
UAR: 0.49890003640003633
ACC: 0.49898921832884097
F1: 0.4729787379752589
train_loss: 1.023268763552007
val_loss: 1.399303674697876

Dev results at epoch 6:
UAR: 0.5083424333424333
ACC: 0.508423180592992
F1: 0.5030610696656189
train_loss: 0.9531547815665893
val_loss: 1.3961963653564453

Dev results at epoch 7:
UAR: 0.4937881062881063
ACC: 0.4939353099730458
F1: 0.4566905544787036
train_loss: 0.9020346717872707
val_loss: 1.6746047735214233

Dev results at epoch 8:
UAR: 0.5339703339703339
ACC: 0.5340296495956873
F1: 0.5125948312993954
train_loss: 0.8551696802127812
val_loss: 1.3380513191223145

Dev results at epoch 9:
UAR: 0.5037116662116662
ACC: 0.5037061994609164
F1: 0.4902769700606312
train_loss: 0.8078202050166441
val_loss: 1.599274754524231

Dev results at epoch 10:
UAR: 0.5184502684502685
ACC: 0.5185309973045822
F1: 0.4965945882527157
train_loss: 0.7619123666420289
val_loss: 1.4459275007247925

Dev results at epoch 11:
UAR: 0.5309115934115934
ACC: 0.5309973045822103
F1: 0.4929093095873401
train_loss: 0.7411275983778471
val_loss: 1.4011332988739014

Dev results at epoch 12:
UAR: 0.5683399308399308
ACC: 0.5683962264150944
F1: 0.5673411496170538
train_loss: 0.7133313912262486
val_loss: 1.2947765588760376

Dev results at epoch 13:
UAR: 0.5289266539266541
ACC: 0.5289757412398922
F1: 0.5261055119405229
train_loss: 0.666979510537674
val_loss: 1.503127932548523

Dev results at epoch 14:
UAR: 0.5656383656383656
ACC: 0.5657008086253369
F1: 0.5561775191143374
train_loss: 0.64546719422182
val_loss: 1.2841193675994873

Dev results at epoch 15:
UAR: 0.5542895167895168
ACC: 0.5542452830188679
F1: 0.5467741379084614
train_loss: 0.6057643506501003
val_loss: 1.3563735485076904

Dev results at epoch 16:
UAR: 0.5572754572754574
ACC: 0.557277628032345
F1: 0.5431823630054069
train_loss: 0.5963788295051623
val_loss: 1.4103212356567383

Dev results at epoch 17:
UAR: 0.5291564291564291
ACC: 0.5293126684636119
F1: 0.5094976455532773
train_loss: 0.5594995075416456
val_loss: 1.6093858480453491

Dev results at epoch 18:
UAR: 0.5471801346801347
ACC: 0.5471698113207547
F1: 0.5403001956097537
train_loss: 0.530037196606978
val_loss: 1.450953722000122

Dev results at epoch 19:
UAR: 0.562005187005187
ACC: 0.5619946091644205
F1: 0.5539746946355203
train_loss: 0.5149200917024247
val_loss: 1.456835150718689

Dev results at epoch 20:
UAR: 0.5488590863590863
ACC: 0.5488544474393531
F1: 0.5412186129284053
train_loss: 0.4895523631815102
val_loss: 1.5442734956741333

Dev results at epoch 21:
UAR: 0.5700416325416325
ACC: 0.5700808625336927
F1: 0.5632572202178376
train_loss: 0.4743540023644492
val_loss: 1.4601558446884155

Dev results at epoch 22:
UAR: 0.5524126399126399
ACC: 0.5525606469002695
F1: 0.5431926020358829
train_loss: 0.4570605121680961
val_loss: 1.5674827098846436

Dev results at epoch 23:
UAR: 0.55992355992356
ACC: 0.5599730458221024
F1: 0.5536092437339832
train_loss: 0.44108177829887996
val_loss: 1.6755560636520386

Dev results at epoch 24:
UAR: 0.5524251524251523
ACC: 0.5525606469002695
F1: 0.5370789855889989
train_loss: 0.41147430322612
val_loss: 1.596476674079895

Dev results at epoch 25:
UAR: 0.5417474292474292
ACC: 0.5417789757412399
F1: 0.5280111172371148
train_loss: 0.39252099825361614
val_loss: 1.8346028327941895

Dev results at epoch 26:
UAR: 0.5720754845754846
ACC: 0.5721024258760108
F1: 0.5682387067924382
train_loss: 0.3895597575682579
val_loss: 1.4837450981140137

Dev results at epoch 27:
UAR: 0.5639958139958141
ACC: 0.5640161725067385
F1: 0.5586087879574495
train_loss: 0.36222959544300554
val_loss: 1.580049991607666

Dev results at epoch 28:
UAR: 0.5599974974974974
ACC: 0.5599730458221024
F1: 0.5551343674945015
train_loss: 0.34598390279254554
val_loss: 1.7199716567993164

Dev results at epoch 29:
UAR: 0.5586495586495586
ACC: 0.5586253369272237
F1: 0.5548386783525798
train_loss: 0.3394495974607416
val_loss: 1.6311877965927124

Dev results at epoch 30:
UAR: 0.5378162253162253
ACC: 0.5377358490566038
F1: 0.5208612740114705
train_loss: 0.31758820948501426
val_loss: 1.7556476593017578

Dev results at epoch 31:
UAR: 0.5683626808626808
ACC: 0.5683962264150944
F1: 0.5671076429455391
train_loss: 0.306348808249512
val_loss: 1.616668462753296

Dev results at epoch 32:
UAR: 0.5898364273364274
ACC: 0.5899595687331537
F1: 0.5834820053349984
train_loss: 0.29876283052049896
val_loss: 1.5485278367996216

Dev results at epoch 33:
UAR: 0.5706570206570207
ACC: 0.5707547169811321
F1: 0.5705131132767969
train_loss: 0.2778705716995098
val_loss: 1.6769670248031616

Dev results at epoch 34:
UAR: 0.5536013286013286
ACC: 0.5535714285714286
F1: 0.5384060825834138
train_loss: 0.28838388359799283
val_loss: 1.8396990299224854

Dev results at epoch 35:
UAR: 0.5818716443716444
ACC: 0.5818733153638814
F1: 0.5753060625031347
train_loss: 0.2613717140128488
val_loss: 1.6384098529815674

Dev results at epoch 36:
UAR: 0.5650366275366275
ACC: 0.5650269541778976
F1: 0.561290797050177
train_loss: 0.2500100994828282
val_loss: 1.7806724309921265

Dev results at epoch 37:
UAR: 0.5918964418964419
ACC: 0.5919811320754716
F1: 0.5821410771093797
train_loss: 0.24508115992735205
val_loss: 1.591929316520691

Dev results at epoch 38:
UAR: 0.5536138411138412
ACC: 0.5535714285714286
F1: 0.5422590889780435
train_loss: 0.23766768822085885
val_loss: 1.7754783630371094

Dev results at epoch 39:
UAR: 0.551885976885977
ACC: 0.5518867924528302
F1: 0.5496540068910709
train_loss: 0.22857168938522948
val_loss: 1.8773226737976074

Dev results at epoch 40:
UAR: 0.5744005369005368
ACC: 0.5744609164420486
F1: 0.5709964605071397
train_loss: 0.2170577804266741
val_loss: 1.7810293436050415

Dev results at epoch 41:
UAR: 0.5740672490672492
ACC: 0.5741239892183289
F1: 0.5712299973706885
train_loss: 0.21070048829726234
val_loss: 1.7620625495910645

Dev results at epoch 42:
UAR: 0.5817374192374193
ACC: 0.5818733153638814
F1: 0.5720750940399151
train_loss: 0.1911916016363128
val_loss: 1.7930909395217896

Dev results at epoch 43:
UAR: 0.5687573937573938
ACC: 0.568733153638814
F1: 0.5647486360488394
train_loss: 0.176735494871499
val_loss: 2.057188034057617

Dev results at epoch 44:
UAR: 0.5677302302302302
ACC: 0.567722371967655
F1: 0.5662200333844172
train_loss: 0.19225626939508683
val_loss: 1.8133580684661865

Dev results at epoch 45:
UAR: 0.5576576576576577
ACC: 0.5576145552560647
F1: 0.5466212601034343
train_loss: 0.17678894971434414
val_loss: 2.014309883117676

Dev results at epoch 46:
UAR: 0.5532032032032032
ACC: 0.5532345013477089
F1: 0.5481632464751245
train_loss: 0.15871801657734474
val_loss: 2.051584482192993

Dev results at epoch 47:
UAR: 0.5356788606788607
ACC: 0.5357142857142857
F1: 0.5260814211274123
train_loss: 0.18266579995992224
val_loss: 2.3408894538879395

Dev results at epoch 48:
UAR: 0.5596585221585222
ACC: 0.5596361185983828
F1: 0.5569555342520583
train_loss: 0.15802067886922777
val_loss: 2.059314250946045

Dev results at epoch 49:
UAR: 0.5693113568113568
ACC: 0.5694070080862533
F1: 0.5645649650776741
train_loss: 0.15621084349460895
val_loss: 1.8922464847564697

Dev results at epoch 50:
UAR: 0.5997474747474748
ACC: 0.5997304582210242
F1: 0.5995473237815389
train_loss: 0.14018761744948888
val_loss: 1.7245824337005615

Best dev results found at epoch 50:
UAR: 0.5997474747474748
ACC: 0.5997304582210242
F1: 0.5995473237815389
train_loss: 0.14018761744948888
val_loss: 1.7245824337005615

Best test results:
UAR: 0.5997474747474748
ACC: 0.5997304582210242
F1: 0.5995473237815389

Running experiment 13/84

Running NeuralBench with Configuration:
device:		 cuda:0
state:		 None
approach:	 cnn10
category:	 None
batch_size:	 16
epochs:		 50
learning_rate:	 0.0001
seed:		 42
optimizer:	 KFACOptimizer
exclude cities:	 None

-----------------hi---------------
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_train.csv
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_evaluate.csv
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_evaluate.csv
Dev results at epoch 1:
UAR: 0.3001831376831377
ACC: 0.3002021563342318
F1: 0.27047218158652303
train_loss: 2.758083825941621
val_loss: 1.9014369249343872

Dev results at epoch 2:
UAR: 0.37443466193466196
ACC: 0.37432614555256066
F1: 0.3633765662729172
train_loss: 1.5605356511654587
val_loss: 1.6848455667495728

Dev results at epoch 3:
UAR: 0.4228080353080353
ACC: 0.42284366576819404
F1: 0.4082715373201233
train_loss: 1.300486731228823
val_loss: 1.5360132455825806

Dev results at epoch 4:
UAR: 0.45417235417235424
ACC: 0.45417789757412397
F1: 0.4501731960024329
train_loss: 1.1522978713217469
val_loss: 1.4600974321365356

Dev results at epoch 5:
UAR: 0.44366298116298114
ACC: 0.443733153638814
F1: 0.44812420201176095
train_loss: 1.0119166710805512
val_loss: 1.5146297216415405

Dev results at epoch 6:
UAR: 0.4985667485667486
ACC: 0.49865229110512127
F1: 0.48815729618924336
train_loss: 0.9256497569305381
val_loss: 1.3662461042404175

Dev results at epoch 7:
UAR: 0.5006688506688506
ACC: 0.5006738544474394
F1: 0.49936608999409404
train_loss: 0.8203619676732798
val_loss: 1.3743507862091064

Dev results at epoch 8:
UAR: 0.49627354627354625
ACC: 0.49629380053908356
F1: 0.4880987345782004
train_loss: 0.7309650454461096
val_loss: 1.3908880949020386

Dev results at epoch 9:
UAR: 0.5167895167895168
ACC: 0.5168463611859838
F1: 0.5104993256285776
train_loss: 0.6502447953492505
val_loss: 1.3631900548934937

Dev results at epoch 10:
UAR: 0.5444194194194194
ACC: 0.5444743935309974
F1: 0.5387135117447059
train_loss: 0.5902661515265396
val_loss: 1.3450443744659424

Dev results at epoch 11:
UAR: 0.5306147056147056
ACC: 0.5306603773584906
F1: 0.529211988609529
train_loss: 0.5263400780717669
val_loss: 1.4409351348876953

Dev results at epoch 12:
UAR: 0.551529939029939
ACC: 0.5515498652291105
F1: 0.5467191627363771
train_loss: 0.48652740244466686
val_loss: 1.4384422302246094

Dev results at epoch 13:
UAR: 0.5396965146965147
ACC: 0.5397574123989218
F1: 0.53744882761184
train_loss: 0.43552213186933686
val_loss: 1.5087404251098633

Dev results at epoch 14:
UAR: 0.5410683410683411
ACC: 0.5411051212938005
F1: 0.5369638057876132
train_loss: 0.38528038789214136
val_loss: 1.5965709686279297

Dev results at epoch 15:
UAR: 0.5494653744653745
ACC: 0.5495283018867925
F1: 0.5434722360708346
train_loss: 0.36698792230888333
val_loss: 1.5104377269744873

Dev results at epoch 16:
UAR: 0.5474155974155974
ACC: 0.5475067385444744
F1: 0.5413965746032837
train_loss: 0.34498483100895344
val_loss: 1.632258415222168

Dev results at epoch 17:
UAR: 0.5552245427245428
ACC: 0.555256064690027
F1: 0.5555096289793829
train_loss: 0.3244762820728285
val_loss: 1.5838637351989746

Dev results at epoch 18:
UAR: 0.5612623987623988
ACC: 0.5613207547169812
F1: 0.555755975567091
train_loss: 0.29094606335621587
val_loss: 1.6508498191833496

Dev results at epoch 19:
UAR: 0.5538481663481664
ACC: 0.5539083557951483
F1: 0.5484571489039729
train_loss: 0.27230529424084726
val_loss: 1.8205643892288208

Dev results at epoch 20:
UAR: 0.549527937027937
ACC: 0.5495283018867925
F1: 0.5482136026819475
train_loss: 0.2603090996731324
val_loss: 1.78023362159729

Dev results at epoch 21:
UAR: 0.5619676494676494
ACC: 0.5619946091644205
F1: 0.555246126942359
train_loss: 0.23062895796606306
val_loss: 1.9300639629364014

Dev results at epoch 22:
UAR: 0.5302336427336427
ACC: 0.5303234501347709
F1: 0.5262579654675725
train_loss: 0.22504188689293356
val_loss: 2.004565715789795

Dev results at epoch 23:
UAR: 0.5707593957593957
ACC: 0.5707547169811321
F1: 0.5684572550993402
train_loss: 0.22840224499926226
val_loss: 1.8822184801101685

Dev results at epoch 24:
UAR: 0.5616366366366367
ACC: 0.5616576819407008
F1: 0.5555628271942836
train_loss: 0.20272192276026393
val_loss: 1.9116297960281372

Dev results at epoch 25:
UAR: 0.5502206752206752
ACC: 0.5502021563342318
F1: 0.5476687850681821
train_loss: 0.19838309136031565
val_loss: 1.9794942140579224

Dev results at epoch 26:
UAR: 0.5764719264719265
ACC: 0.5764824797843666
F1: 0.5755373933778672
train_loss: 0.199536606583548
val_loss: 2.0223116874694824

Dev results at epoch 27:
UAR: 0.5595595595595596
ACC: 0.5596361185983828
F1: 0.5564784641574838
train_loss: 0.21694791163419205
val_loss: 2.1226046085357666

Dev results at epoch 28:
UAR: 0.5542133042133041
ACC: 0.5542452830188679
F1: 0.5525211577997566
train_loss: 0.18384487065339924
val_loss: 2.2399380207061768

Dev results at epoch 29:
UAR: 0.5518427518427519
ACC: 0.5518867924528302
F1: 0.5483040547333267
train_loss: 0.17934424018097683
val_loss: 2.2939329147338867

Dev results at epoch 30:
UAR: 0.5454386204386205
ACC: 0.5454851752021563
F1: 0.5380780657905587
train_loss: 0.2144515993378156
val_loss: 2.3978424072265625

Dev results at epoch 31:
UAR: 0.5636795886795887
ACC: 0.5636792452830188
F1: 0.5586003042211904
train_loss: 0.20072828438815757
val_loss: 2.2211718559265137

Dev results at epoch 32:
UAR: 0.5690702065702066
ACC: 0.5690700808625337
F1: 0.5670269070892809
train_loss: 0.19130863561409656
val_loss: 2.2982189655303955

Dev results at epoch 33:
UAR: 0.5613010738010739
ACC: 0.5613207547169812
F1: 0.555294272970654
train_loss: 0.20514289114249812
val_loss: 2.4072844982147217

Dev results at epoch 34:
UAR: 0.5546114296114296
ACC: 0.5545822102425876
F1: 0.5444501350158935
train_loss: 0.17365294308636342
val_loss: 2.3296117782592773

Dev results at epoch 35:
UAR: 0.5626296751296752
ACC: 0.5626684636118598
F1: 0.5569533110127161
train_loss: 0.1550961754155182
val_loss: 2.675262689590454

Dev results at epoch 36:
UAR: 0.5683888433888434
ACC: 0.5683962264150944
F1: 0.5608110975921827
train_loss: 0.16857576964610818
val_loss: 2.5533242225646973

Dev results at epoch 37:
UAR: 0.5677108927108928
ACC: 0.567722371967655
F1: 0.5617792101009456
train_loss: 0.14245929592485723
val_loss: 2.6056315898895264

Dev results at epoch 38:
UAR: 0.5646965146965147
ACC: 0.5646900269541779
F1: 0.5600144460592784
train_loss: 0.17507037412581106
val_loss: 2.6218245029449463

Dev results at epoch 39:
UAR: 0.5720925470925471
ACC: 0.5721024258760108
F1: 0.5696134778034077
train_loss: 0.16140178801800698
val_loss: 2.558314800262451

Dev results at epoch 40:
UAR: 0.5623418873418873
ACC: 0.5623315363881402
F1: 0.5608506663161215
train_loss: 0.17983977530388437
val_loss: 2.714743137359619

Dev results at epoch 41:
UAR: 0.5559127309127309
ACC: 0.5559299191374663
F1: 0.5495006395612554
train_loss: 0.16792628658864217
val_loss: 2.8744521141052246

Dev results at epoch 42:
UAR: 0.5706649831649833
ACC: 0.5707547169811321
F1: 0.5619718049088883
train_loss: 0.15659928346988355
val_loss: 2.6484375

Dev results at epoch 43:
UAR: 0.5861679861679862
ACC: 0.5862533692722371
F1: 0.5763424045491021
train_loss: 0.13252556245921518
val_loss: 2.533884286880493

Dev results at epoch 44:
UAR: 0.5417178542178542
ACC: 0.5417789757412399
F1: 0.5330585787502382
train_loss: 0.13088976149293075
val_loss: 3.2531237602233887

Dev results at epoch 45:
UAR: 0.553536491036491
ACC: 0.5535714285714286
F1: 0.5474264348504558
train_loss: 0.15186114749003213
val_loss: 3.074615478515625

Dev results at epoch 46:
UAR: 0.5781531531531531
ACC: 0.578167115902965
F1: 0.5749421889391546
train_loss: 0.14828750810047578
val_loss: 2.73213267326355

Dev results at epoch 47:
UAR: 0.5697413322413323
ACC: 0.569743935309973
F1: 0.5649862539174538
train_loss: 0.15116811396895424
val_loss: 2.7459592819213867

Dev results at epoch 48:
UAR: 0.5717069342069341
ACC: 0.5717654986522911
F1: 0.5676142685276843
train_loss: 0.1476591471577484
val_loss: 2.795358180999756

Dev results at epoch 49:
UAR: 0.5818898443898444
ACC: 0.5818733153638814
F1: 0.5789898628594125
train_loss: 0.1554033209381961
val_loss: 2.7482752799987793

Dev results at epoch 50:
UAR: 0.5703999453999454
ACC: 0.5704177897574124
F1: 0.5669020224627574
train_loss: 0.1373690734989211
val_loss: 3.088139295578003

Best dev results found at epoch 43:
UAR: 0.5861679861679862
ACC: 0.5862533692722371
F1: 0.5763424045491021
train_loss: 0.13252556245921518
val_loss: 2.533884286880493

Best test results:
UAR: 0.5861679861679862
ACC: 0.5862533692722371
F1: 0.5763424045491021

Running experiment 14/84

Running NeuralBench with Configuration:
device:		 cuda:0
state:		 None
approach:	 cnn10
category:	 None
batch_size:	 16
epochs:		 50
learning_rate:	 0.0001
seed:		 42
optimizer:	 GDTUO-Adam-Adam
exclude cities:	 None

-----------------hi---------------
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_train.csv
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_evaluate.csv
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_evaluate.csv
Dev results at epoch 1:
UAR: 0.347521385021385
ACC: 0.3477088948787062
F1: 0.29304961801706697
train_loss: 1.672168644637996
val_loss: 2.037886619567871

Dev results at epoch 2:
UAR: 0.3591261716261716
ACC: 0.3591644204851752
F1: 0.31947272420620304
train_loss: 1.303199702658331
val_loss: 2.216026544570923

Dev results at epoch 3:
UAR: 0.45010465010465006
ACC: 0.4501347708894879
F1: 0.4054563751428585
train_loss: 1.1277327501691903
val_loss: 1.6431074142456055

Dev results at epoch 4:
UAR: 0.5144769769769769
ACC: 0.514487870619946
F1: 0.4837964832602689
train_loss: 1.017410125451126
val_loss: 1.430441975593567

Dev results at epoch 5:
UAR: 0.4995961870961871
ACC: 0.4996630727762803
F1: 0.4814500540086339
train_loss: 0.9333397379445866
val_loss: 1.4645785093307495

Dev results at epoch 6:
UAR: 0.4810924560924561
ACC: 0.4811320754716981
F1: 0.4562710953376957
train_loss: 0.8515122081883858
val_loss: 1.5334208011627197

Dev results at epoch 7:
UAR: 0.48992515242515233
ACC: 0.4898921832884097
F1: 0.47011768889923766
train_loss: 0.8403871202455216
val_loss: 1.5339109897613525

Dev results at epoch 8:
UAR: 0.505638593138593
ACC: 0.5057277628032345
F1: 0.48179362688159155
train_loss: 0.7788129025240261
val_loss: 1.6096644401550293

Dev results at epoch 9:
UAR: 0.5353285103285103
ACC: 0.535377358490566
F1: 0.5149703827644277
train_loss: 0.7512939459679463
val_loss: 1.335091471672058

Dev results at epoch 10:
UAR: 0.5332696332696332
ACC: 0.5333557951482479
F1: 0.518151935252266
train_loss: 0.6647290526489212
val_loss: 1.4461228847503662

Dev results at epoch 11:
UAR: 0.5208674583674584
ACC: 0.52088948787062
F1: 0.5092322372177576
train_loss: 0.6458064322823921
val_loss: 1.5074042081832886

Dev results at epoch 12:
UAR: 0.5330409955409955
ACC: 0.5330188679245284
F1: 0.5140679009862723
train_loss: 0.633189851492814
val_loss: 1.4962921142578125

Dev results at epoch 13:
UAR: 0.5548605423605424
ACC: 0.5549191374663073
F1: 0.5433505559718613
train_loss: 0.5736880682383206
val_loss: 1.432623267173767

Dev results at epoch 14:
UAR: 0.5316668941668942
ACC: 0.5316711590296496
F1: 0.5103342356730531
train_loss: 0.6126088221970293
val_loss: 1.5028010606765747

Dev results at epoch 15:
UAR: 0.5460631085631087
ACC: 0.5461590296495957
F1: 0.5323871951699592
train_loss: 0.5597756368973275
val_loss: 1.4199578762054443

Dev results at epoch 16:
UAR: 0.5174959049959049
ACC: 0.5175202156334232
F1: 0.4949386732412159
train_loss: 0.5245893201689403
val_loss: 1.5958291292190552

Dev results at epoch 17:
UAR: 0.4821730821730822
ACC: 0.48214285714285715
F1: 0.4526873394648018
train_loss: 0.4894956708859059
val_loss: 1.7061139345169067

Dev results at epoch 18:
UAR: 0.577478614978615
ACC: 0.5774932614555256
F1: 0.5699107444149492
train_loss: 0.5126642915937636
val_loss: 1.2990520000457764

Dev results at epoch 19:
UAR: 0.5764173264173265
ACC: 0.5764824797843666
F1: 0.5698304307322635
train_loss: 0.41581398028483507
val_loss: 1.3482974767684937

Dev results at epoch 20:
UAR: 0.5552165802165803
ACC: 0.555256064690027
F1: 0.5483591434146157
train_loss: 0.3862808218646159
val_loss: 1.4431945085525513

Dev results at epoch 21:
UAR: 0.5787799162799163
ACC: 0.5788409703504043
F1: 0.5724290934463852
train_loss: 0.3861802176648126
val_loss: 1.3886713981628418

Dev results at epoch 22:
UAR: 0.5548673673673674
ACC: 0.5549191374663073
F1: 0.5407166794027805
train_loss: 0.3780991647942984
val_loss: 1.4820209741592407

Dev results at epoch 23:
UAR: 0.5818579943579943
ACC: 0.5818733153638814
F1: 0.5751697123035425
train_loss: 0.373118533203453
val_loss: 1.4188543558120728

Dev results at epoch 24:
UAR: 0.529596642096642
ACC: 0.5296495956873315
F1: 0.5077450249032128
train_loss: 0.3293496693430078
val_loss: 1.706623911857605

Dev results at epoch 25:
UAR: 0.5337405587405587
ACC: 0.5336927223719676
F1: 0.5220836604321288
train_loss: 0.3396062549685831
val_loss: 1.6928752660751343

Dev results at epoch 26:
UAR: 0.5659762034762035
ACC: 0.5660377358490566
F1: 0.5594276112765673
train_loss: 0.3024132261127404
val_loss: 1.467267394065857

Dev results at epoch 27:
UAR: 0.537940212940213
ACC: 0.5380727762803235
F1: 0.5205588651060011
train_loss: 0.29004003826149005
val_loss: 1.7092666625976562

Dev results at epoch 28:
UAR: 0.5411411411411412
ACC: 0.5411051212938005
F1: 0.53811988005034
train_loss: 0.37078147282544416
val_loss: 1.6113873720169067

Dev results at epoch 29:
UAR: 0.5700495950495951
ACC: 0.5700808625336927
F1: 0.5622223636579555
train_loss: 0.29812066611179916
val_loss: 1.4687546491622925

Dev results at epoch 30:
UAR: 0.5663959413959414
ACC: 0.5663746630727763
F1: 0.5547769116961124
train_loss: 0.2697309436018388
val_loss: 1.614777684211731

Dev results at epoch 31:
UAR: 0.567053417053417
ACC: 0.5670485175202157
F1: 0.558908364573295
train_loss: 0.23195523543993837
val_loss: 1.5339722633361816

Dev results at epoch 32:
UAR: 0.5869483119483119
ACC: 0.5869272237196765
F1: 0.5838261524637156
train_loss: 0.21560059815329444
val_loss: 1.4491629600524902

Dev results at epoch 33:
UAR: 0.5583151333151333
ACC: 0.558288409703504
F1: 0.5507832365165035
train_loss: 0.2667541004981918
val_loss: 1.5950886011123657

Dev results at epoch 34:
UAR: 0.5794362544362543
ACC: 0.5795148247978437
F1: 0.5717207320375117
train_loss: 0.23118800552346383
val_loss: 1.4249626398086548

Dev results at epoch 35:
UAR: 0.5730958230958232
ACC: 0.5731132075471698
F1: 0.5638404257660121
train_loss: 0.23423437076702902
val_loss: 1.5541493892669678

Dev results at epoch 36:
UAR: 0.5731083356083355
ACC: 0.5731132075471698
F1: 0.567918829329535
train_loss: 0.19492430490828871
val_loss: 1.5740119218826294

Dev results at epoch 37:
UAR: 0.5889070889070889
ACC: 0.5889487870619946
F1: 0.5815708136785733
train_loss: 0.19090123816402918
val_loss: 1.4845749139785767

Dev results at epoch 38:
UAR: 0.5765015015015015
ACC: 0.5764824797843666
F1: 0.5731018264122458
train_loss: 0.19644531786851457
val_loss: 1.5947861671447754

Dev results at epoch 39:
UAR: 0.5396430521430521
ACC: 0.5397574123989218
F1: 0.5319280560825506
train_loss: 0.18916890976944126
val_loss: 1.8746957778930664

Dev results at epoch 40:
UAR: 0.5417258167258168
ACC: 0.5417789757412399
F1: 0.5365664183395981
train_loss: 0.1909833224372936
val_loss: 1.6681309938430786

Dev results at epoch 41:
UAR: 0.5683615433615433
ACC: 0.5683962264150944
F1: 0.5625098466148897
train_loss: 0.20580857202708336
val_loss: 1.5843000411987305

Dev results at epoch 42:
UAR: 0.5559297934297934
ACC: 0.5559299191374663
F1: 0.5518135765955865
train_loss: 0.16944055588764456
val_loss: 1.8099642992019653

Dev results at epoch 43:
UAR: 0.5543736918736919
ACC: 0.5542452830188679
F1: 0.5489353404448539
train_loss: 0.1594986818007536
val_loss: 1.7182589769363403

Dev results at epoch 44:
UAR: 0.5741047866047866
ACC: 0.5741239892183289
F1: 0.5730954376783715
train_loss: 0.14771475529251246
val_loss: 1.7083570957183838

Dev results at epoch 45:
UAR: 0.4878446628446628
ACC: 0.48787061994609165
F1: 0.47044472940955745
train_loss: 0.13975236832536544
val_loss: 2.3442893028259277

Dev results at epoch 46:
UAR: 0.5723780598780599
ACC: 0.5724393530997305
F1: 0.5648665747519629
train_loss: 0.15322385036401484
val_loss: 1.7279952764511108

Dev results at epoch 47:
UAR: 0.5801710801710802
ACC: 0.5801886792452831
F1: 0.5727437362822435
train_loss: 0.28748587929224434
val_loss: 1.6230796575546265

Dev results at epoch 48:
UAR: 0.5839305214305215
ACC: 0.5838948787061995
F1: 0.5728848480876041
train_loss: 0.13002825128757325
val_loss: 1.6168545484542847

Dev results at epoch 49:
UAR: 0.5201496951496952
ACC: 0.5202156334231806
F1: 0.5114336427169349
train_loss: 0.1858285764330424
val_loss: 1.926930546760559

Dev results at epoch 50:
UAR: 0.5508076258076258
ACC: 0.5508760107816711
F1: 0.544933201585921
train_loss: 0.12223515571345749
val_loss: 1.9320963621139526

Best dev results found at epoch 37:
UAR: 0.5889070889070889
ACC: 0.5889487870619946
F1: 0.5815708136785733
train_loss: 0.19090123816402918
val_loss: 1.4845749139785767

Best test results:
UAR: 0.5889070889070889
ACC: 0.5889487870619946
F1: 0.5815708136785733

Running experiment 15/84

Running NeuralBench with Configuration:
device:		 cuda:0
state:		 None
approach:	 cnn10
category:	 None
batch_size:	 16
epochs:		 50
learning_rate:	 0.0001
seed:		 42
optimizer:	 Adam
exclude cities:	 None

-----------------hi---------------
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_train.csv
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_evaluate.csv
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_evaluate.csv
Dev results at epoch 1:
UAR: 0.39807307307307305
ACC: 0.39824797843665766
F1: 0.3649937006568436
train_loss: 1.6178446775312958
val_loss: 1.7585731744766235

Dev results at epoch 2:
UAR: 0.467042042042042
ACC: 0.4669811320754717
F1: 0.4300479902858075
train_loss: 1.209194807525626
val_loss: 1.6030834913253784

Dev results at epoch 3:
UAR: 0.47272272272272275
ACC: 0.4727088948787062
F1: 0.4356252234687206
train_loss: 1.0429849922315635
val_loss: 1.5306235551834106

Dev results at epoch 4:
UAR: 0.511526299026299
ACC: 0.511455525606469
F1: 0.4816890908352803
train_loss: 0.9251117838412216
val_loss: 1.4080872535705566

Dev results at epoch 5:
UAR: 0.5305589680589681
ACC: 0.5306603773584906
F1: 0.5197662227888115
train_loss: 0.8330282204339594
val_loss: 1.3370312452316284

Dev results at epoch 6:
UAR: 0.48643416143416135
ACC: 0.4865229110512129
F1: 0.4603562544945586
train_loss: 0.7794729405149972
val_loss: 1.6347829103469849

Dev results at epoch 7:
UAR: 0.5128696878696879
ACC: 0.5128032345013477
F1: 0.5047836512264507
train_loss: 0.7152018059569946
val_loss: 1.4478833675384521

Dev results at epoch 8:
UAR: 0.4981811356811357
ACC: 0.49831536388140163
F1: 0.48617546270093104
train_loss: 0.6611165457574772
val_loss: 1.5626842975616455

Dev results at epoch 9:
UAR: 0.5501353626353626
ACC: 0.5502021563342318
F1: 0.5399192115296141
train_loss: 0.6163864343385517
val_loss: 1.3083125352859497

Dev results at epoch 10:
UAR: 0.48681181181181177
ACC: 0.4868598382749326
F1: 0.4644210203821541
train_loss: 0.5690823363872055
val_loss: 1.7628005743026733

Dev results at epoch 11:
UAR: 0.5026503776503777
ACC: 0.5026954177897575
F1: 0.49912705246445543
train_loss: 0.5287822615461933
val_loss: 1.5955063104629517

Dev results at epoch 12:
UAR: 0.568004368004368
ACC: 0.5680592991913747
F1: 0.5588811959288169
train_loss: 0.5001751583449346
val_loss: 1.345555305480957

Dev results at epoch 13:
UAR: 0.5219799344799345
ACC: 0.5219002695417789
F1: 0.518045634865291
train_loss: 0.466467416812191
val_loss: 1.6036490201950073

Dev results at epoch 14:
UAR: 0.54487441987442
ACC: 0.5448113207547169
F1: 0.5292443057599912
train_loss: 0.4364451584827586
val_loss: 1.545172095298767

Dev results at epoch 15:
UAR: 0.5683501683501684
ACC: 0.5683962264150944
F1: 0.5552534425681455
train_loss: 0.40838616525696725
val_loss: 1.409804344177246

Dev results at epoch 16:
UAR: 0.5424344799344799
ACC: 0.5424528301886793
F1: 0.5327958324577583
train_loss: 0.3897750746215537
val_loss: 1.5105092525482178

Dev results at epoch 17:
UAR: 0.5377445627445627
ACC: 0.5377358490566038
F1: 0.5330505389257612
train_loss: 0.3644736168600986
val_loss: 1.5419559478759766

Dev results at epoch 18:
UAR: 0.5411104286104286
ACC: 0.5411051212938005
F1: 0.5375310802595812
train_loss: 0.3503541583099316
val_loss: 1.5393801927566528

Dev results at epoch 19:
UAR: 0.5196958321958322
ACC: 0.519878706199461
F1: 0.5044460110698101
train_loss: 0.3181307534564538
val_loss: 1.8001770973205566

Dev results at epoch 20:
UAR: 0.5622690872690872
ACC: 0.5623315363881402
F1: 0.5578807113785652
train_loss: 0.29680655157793084
val_loss: 1.555419921875

Dev results at epoch 21:
UAR: 0.5949472199472199
ACC: 0.5950134770889488
F1: 0.587709338874976
train_loss: 0.28055829917937347
val_loss: 1.4268513917922974

Dev results at epoch 22:
UAR: 0.5415711165711166
ACC: 0.5417789757412399
F1: 0.5194866562682618
train_loss: 0.26112929125234297
val_loss: 1.7277464866638184

Dev results at epoch 23:
UAR: 0.5657145782145783
ACC: 0.5657008086253369
F1: 0.5554848103544192
train_loss: 0.2526537550641021
val_loss: 1.6211830377578735

Dev results at epoch 24:
UAR: 0.5198596323596323
ACC: 0.519878706199461
F1: 0.5017632646242902
train_loss: 0.24230707000049187
val_loss: 1.970225214958191

Dev results at epoch 25:
UAR: 0.5097199472199472
ACC: 0.5097708894878706
F1: 0.49323308029962726
train_loss: 0.2191088942689277
val_loss: 2.1348392963409424

Dev results at epoch 26:
UAR: 0.5403107653107653
ACC: 0.5404312668463612
F1: 0.5274801852769121
train_loss: 0.20283121355987427
val_loss: 1.8326427936553955

Dev results at epoch 27:
UAR: 0.5639298389298391
ACC: 0.5640161725067385
F1: 0.5535143526394981
train_loss: 0.1884774442267138
val_loss: 1.6988061666488647

Dev results at epoch 28:
UAR: 0.5889014014014015
ACC: 0.5889487870619946
F1: 0.5804037483227747
train_loss: 0.19791444913320935
val_loss: 1.5898720026016235

Dev results at epoch 29:
UAR: 0.5588770588770589
ACC: 0.5589622641509434
F1: 0.5501223041555079
train_loss: 0.18225528763442855
val_loss: 1.7834303379058838

Dev results at epoch 30:
UAR: 0.5589851214851215
ACC: 0.5589622641509434
F1: 0.5510878161938868
train_loss: 0.17250866597419112
val_loss: 1.784245491027832

Dev results at epoch 31:
UAR: 0.5518950768950768
ACC: 0.5518867924528302
F1: 0.5474845102112454
train_loss: 0.1566841721903844
val_loss: 1.83577299118042

Dev results at epoch 32:
UAR: 0.5649661024661025
ACC: 0.5650269541778976
F1: 0.5628025838386983
train_loss: 0.1554703832708538
val_loss: 1.7376052141189575

Dev results at epoch 33:
UAR: 0.5746553371553371
ACC: 0.5747978436657682
F1: 0.5653113559263169
train_loss: 0.14432676246961557
val_loss: 1.7813113927841187

Dev results at epoch 34:
UAR: 0.5303792428792429
ACC: 0.5303234501347709
F1: 0.5111828077420986
train_loss: 0.13629476327122642
val_loss: 2.244788408279419

Dev results at epoch 35:
UAR: 0.563991263991264
ACC: 0.5640161725067385
F1: 0.5518655071064931
train_loss: 0.13987603326854034
val_loss: 1.8773064613342285

Dev results at epoch 36:
UAR: 0.5704033579033579
ACC: 0.5704177897574124
F1: 0.5602134929651552
train_loss: 0.13973576628591305
val_loss: 1.795118808746338

Dev results at epoch 37:
UAR: 0.5808205933205933
ACC: 0.5808625336927223
F1: 0.5755654775950334
train_loss: 0.12079580825404664
val_loss: 1.7546907663345337

Dev results at epoch 38:
UAR: 0.5744380744380745
ACC: 0.5744609164420486
F1: 0.5640771405364637
train_loss: 0.13061820583088368
val_loss: 1.8820126056671143

Dev results at epoch 39:
UAR: 0.5497702247702247
ACC: 0.5498652291105122
F1: 0.531196018287919
train_loss: 0.11024314271436016
val_loss: 2.1454992294311523

Dev results at epoch 40:
UAR: 0.5642847392847393
ACC: 0.5643530997304582
F1: 0.5534695997737968
train_loss: 0.11129706409383236
val_loss: 1.9018988609313965

Dev results at epoch 41:
UAR: 0.5451940576940577
ACC: 0.5451482479784366
F1: 0.5401616060956395
train_loss: 0.11920504455154875
val_loss: 2.104830503463745

Dev results at epoch 42:
UAR: 0.5811368186368187
ACC: 0.581199460916442
F1: 0.5709206131481558
train_loss: 0.10015901405951552
val_loss: 1.9550633430480957

Dev results at epoch 43:
UAR: 0.5630551005551006
ACC: 0.5630053908355795
F1: 0.5614601603599862
train_loss: 0.10249978228819419
val_loss: 2.001572847366333

Dev results at epoch 44:
UAR: 0.5535444535444536
ACC: 0.5535714285714286
F1: 0.5366341110959847
train_loss: 0.10045006370090827
val_loss: 2.323845148086548

Dev results at epoch 45:
UAR: 0.5294214669214669
ACC: 0.5293126684636119
F1: 0.5221373403426458
train_loss: 0.10092056175986708
val_loss: 2.3383994102478027

Dev results at epoch 46:
UAR: 0.5619278369278369
ACC: 0.5619946091644205
F1: 0.5564835667939156
train_loss: 0.09214978119735004
val_loss: 2.069413185119629

Dev results at epoch 47:
UAR: 0.5710835835835837
ACC: 0.5710916442048517
F1: 0.5567010765427709
train_loss: 0.09557773058226957
val_loss: 2.080092191696167

Dev results at epoch 48:
UAR: 0.5767881517881517
ACC: 0.5768194070080862
F1: 0.5611202237292747
train_loss: 0.09106700495512193
val_loss: 1.9913445711135864

Dev results at epoch 49:
UAR: 0.5848632723632724
ACC: 0.5849056603773585
F1: 0.5819995897963202
train_loss: 0.09246769990387425
val_loss: 1.8651963472366333

Dev results at epoch 50:
UAR: 0.5475543725543726
ACC: 0.5475067385444744
F1: 0.543138841211477
train_loss: 0.08001013980383098
val_loss: 2.190790891647339

Best dev results found at epoch 21:
UAR: 0.5949472199472199
ACC: 0.5950134770889488
F1: 0.587709338874976
train_loss: 0.28055829917937347
val_loss: 1.4268513917922974

Best test results:
UAR: 0.5949472199472199
ACC: 0.5950134770889488
F1: 0.587709338874976

Running experiment 16/84

Running NeuralBench with Configuration:
device:		 cuda:0
state:		 None
approach:	 cnn10
category:	 None
batch_size:	 16
epochs:		 50
learning_rate:	 0.0001
seed:		 42
optimizer:	 SGD
exclude cities:	 None

-----------------hi---------------
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_train.csv
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_evaluate.csv
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_evaluate.csv
Dev results at epoch 1:
UAR: 0.19395645645645646
ACC: 0.1940700808625337
F1: 0.14794043401576268
train_loss: 1.982495431228192
val_loss: 2.669715642929077

Dev results at epoch 2:
UAR: 0.34732573482573487
ACC: 0.3473719676549865
F1: 0.3035131133281307
train_loss: 1.6432364627394616
val_loss: 1.908624291419983

Dev results at epoch 3:
UAR: 0.3485997360997361
ACC: 0.34871967654986524
F1: 0.3017468699913298
train_loss: 1.4569235566282326
val_loss: 2.145829200744629

Dev results at epoch 4:
UAR: 0.4211006461006462
ACC: 0.4211590296495957
F1: 0.38341073128254244
train_loss: 1.3731885148897203
val_loss: 1.6769161224365234

Dev results at epoch 5:
UAR: 0.4452714077714077
ACC: 0.4454177897574124
F1: 0.41271831528972314
train_loss: 1.2989352540052224
val_loss: 1.6859413385391235

Dev results at epoch 6:
UAR: 0.4156508781508782
ACC: 0.41576819407008087
F1: 0.3715129108951559
train_loss: 1.2581341708375553
val_loss: 1.7604799270629883

Dev results at epoch 7:
UAR: 0.4453430703430704
ACC: 0.4454177897574124
F1: 0.41200585050732624
train_loss: 1.2130579807094692
val_loss: 1.7252947092056274

Dev results at epoch 8:
UAR: 0.4271783146783147
ACC: 0.4272237196765499
F1: 0.38756971195191936
train_loss: 1.169450091810434
val_loss: 1.8719980716705322

Dev results at epoch 9:
UAR: 0.46425971425971424
ACC: 0.4642857142857143
F1: 0.4317253151492729
train_loss: 1.131672195654964
val_loss: 1.6269108057022095

Dev results at epoch 10:
UAR: 0.4355742105742106
ACC: 0.4356469002695418
F1: 0.4010299008713745
train_loss: 1.1022413385283087
val_loss: 1.8323204517364502

Dev results at epoch 11:
UAR: 0.4736463736463737
ACC: 0.47371967654986524
F1: 0.45359324585213345
train_loss: 1.0689979395301072
val_loss: 1.5853015184402466

Dev results at epoch 12:
UAR: 0.48711324961324964
ACC: 0.4871967654986523
F1: 0.44282296639528396
train_loss: 1.047275725167505
val_loss: 1.5328235626220703

Dev results at epoch 13:
UAR: 0.46013058513058513
ACC: 0.46024258760107817
F1: 0.42448721210444224
train_loss: 1.0215405490663316
val_loss: 1.7017805576324463

Dev results at epoch 14:
UAR: 0.48106401856401854
ACC: 0.4811320754716981
F1: 0.44660805312901564
train_loss: 0.997168438506973
val_loss: 1.5903077125549316

Dev results at epoch 15:
UAR: 0.49556488306488305
ACC: 0.4956199460916442
F1: 0.46013795558601184
train_loss: 0.9689822962671893
val_loss: 1.5776722431182861

Dev results at epoch 16:
UAR: 0.48138820638820634
ACC: 0.4814690026954178
F1: 0.45109391352558087
train_loss: 0.9428904615043912
val_loss: 1.6065200567245483

Dev results at epoch 17:
UAR: 0.46526412776412773
ACC: 0.46529649595687333
F1: 0.43359860622436724
train_loss: 0.9261146093903265
val_loss: 1.6096999645233154

Dev results at epoch 18:
UAR: 0.49428974428974426
ACC: 0.4942722371967655
F1: 0.46468914446358756
train_loss: 0.9047222950955573
val_loss: 1.5178433656692505

Dev results at epoch 19:
UAR: 0.4857675857675858
ACC: 0.4858490566037736
F1: 0.4622306602396339
train_loss: 0.8833429861519345
val_loss: 1.528847575187683

Dev results at epoch 20:
UAR: 0.4901731276731277
ACC: 0.49022911051212936
F1: 0.4590525633506667
train_loss: 0.8570477488660867
val_loss: 1.632981777191162

Dev results at epoch 21:
UAR: 0.5066691691691692
ACC: 0.5067385444743935
F1: 0.4819128227266608
train_loss: 0.8433616554443506
val_loss: 1.5449305772781372

Dev results at epoch 22:
UAR: 0.5232209482209481
ACC: 0.5232479784366577
F1: 0.4991498857698941
train_loss: 0.8254717011154039
val_loss: 1.4465539455413818

Dev results at epoch 23:
UAR: 0.49863613613613617
ACC: 0.49865229110512127
F1: 0.4716385351233977
train_loss: 0.8084539661156216
val_loss: 1.5973265171051025

Dev results at epoch 24:
UAR: 0.49120029120029124
ACC: 0.4912398921832884
F1: 0.46504521994120146
train_loss: 0.8018204665061125
val_loss: 1.6878132820129395

Dev results at epoch 25:
UAR: 0.46631176631176635
ACC: 0.46630727762803237
F1: 0.42865005263672196
train_loss: 0.7784173400029284
val_loss: 1.9361242055892944

Dev results at epoch 26:
UAR: 0.5036286286286286
ACC: 0.5037061994609164
F1: 0.47460111840283714
train_loss: 0.766896659395266
val_loss: 1.682338833808899

Dev results at epoch 27:
UAR: 0.49449108199108205
ACC: 0.4946091644204852
F1: 0.4647751765910981
train_loss: 0.7474581808841788
val_loss: 1.6351089477539062

Dev results at epoch 28:
UAR: 0.5003514878514878
ACC: 0.5003369272237197
F1: 0.4770811592301456
train_loss: 0.7388159816514995
val_loss: 1.6529912948608398

Dev results at epoch 29:
UAR: 0.47936800436800436
ACC: 0.47944743935309975
F1: 0.44924630827564815
train_loss: 0.7327506097048555
val_loss: 1.7119053602218628

Dev results at epoch 30:
UAR: 0.4966921466921467
ACC: 0.49663072776280326
F1: 0.4707091655181882
train_loss: 0.7190556796384977
val_loss: 1.669831395149231

Dev results at epoch 31:
UAR: 0.42927814177814183
ACC: 0.42924528301886794
F1: 0.411274520596064
train_loss: 0.7048098264349558
val_loss: 1.9751019477844238

Dev results at epoch 32:
UAR: 0.48282373282373287
ACC: 0.4828167115902965
F1: 0.4656726616393446
train_loss: 0.6942247627527034
val_loss: 1.7057993412017822

Dev results at epoch 33:
UAR: 0.5053644553644554
ACC: 0.5053908355795148
F1: 0.4792466421850512
train_loss: 0.6812371735856841
val_loss: 1.7270573377609253

Dev results at epoch 34:
UAR: 0.5047229047229047
ACC: 0.5047169811320755
F1: 0.4760845300882105
train_loss: 0.6557475426250307
val_loss: 1.6968973875045776

Dev results at epoch 35:
UAR: 0.5130937755937756
ACC: 0.5131401617250674
F1: 0.4922690770359421
train_loss: 0.6554682151353646
val_loss: 1.6203949451446533

Dev results at epoch 36:
UAR: 0.5158738283738284
ACC: 0.5158355795148248
F1: 0.4876269024702153
train_loss: 0.6407351552040443
val_loss: 1.6989277601242065

Dev results at epoch 37:
UAR: 0.5117367367367367
ACC: 0.5117924528301887
F1: 0.4919963056837663
train_loss: 0.6341107400627071
val_loss: 1.6374433040618896

Dev results at epoch 38:
UAR: 0.5101146601146601
ACC: 0.5101078167115903
F1: 0.49110747392256365
train_loss: 0.6271315105899503
val_loss: 1.6989699602127075

Dev results at epoch 39:
UAR: 0.5058001183001183
ACC: 0.5057277628032345
F1: 0.4819281259301767
train_loss: 0.616032047062805
val_loss: 1.7610212564468384

Dev results at epoch 40:
UAR: 0.515500728000728
ACC: 0.5154986522911051
F1: 0.4907603467204484
train_loss: 0.6041876995618127
val_loss: 1.6737366914749146

Dev results at epoch 41:
UAR: 0.5084550459550459
ACC: 0.508423180592992
F1: 0.49466729181836533
train_loss: 0.5923268026741646
val_loss: 1.6965968608856201

Dev results at epoch 42:
UAR: 0.5154586404586404
ACC: 0.5154986522911051
F1: 0.4986427038318292
train_loss: 0.5816128985169008
val_loss: 1.67332124710083

Dev results at epoch 43:
UAR: 0.5087337337337338
ACC: 0.5087601078167115
F1: 0.4844921368663505
train_loss: 0.5730989324814402
val_loss: 1.7685997486114502

Dev results at epoch 44:
UAR: 0.5211586586586586
ACC: 0.5212264150943396
F1: 0.5001004144646981
train_loss: 0.5647317323863574
val_loss: 1.7161275148391724

Dev results at epoch 45:
UAR: 0.5087064337064338
ACC: 0.5087601078167115
F1: 0.4823578788962714
train_loss: 0.558049636386241
val_loss: 1.788867712020874

Dev results at epoch 46:
UAR: 0.5188108563108563
ACC: 0.5188679245283019
F1: 0.4988251376665412
train_loss: 0.549350524993287
val_loss: 1.6497817039489746

Dev results at epoch 47:
UAR: 0.5165415415415415
ACC: 0.5165094339622641
F1: 0.49376266269264957
train_loss: 0.5454742820316847
val_loss: 1.7996826171875

Dev results at epoch 48:
UAR: 0.5337610337610338
ACC: 0.5336927223719676
F1: 0.5127249572070216
train_loss: 0.5370193644931363
val_loss: 1.6762819290161133

Dev results at epoch 49:
UAR: 0.5232471107471108
ACC: 0.5232479784366577
F1: 0.5158900221018875
train_loss: 0.5234602541584876
val_loss: 1.6101343631744385

Dev results at epoch 50:
UAR: 0.5518723268723268
ACC: 0.5518867924528302
F1: 0.5370507772393032
train_loss: 0.508607877915531
val_loss: 1.5599029064178467

Best dev results found at epoch 50:
UAR: 0.5518723268723268
ACC: 0.5518867924528302
F1: 0.5370507772393032
train_loss: 0.508607877915531
val_loss: 1.5599029064178467

Best test results:
UAR: 0.5518723268723268
ACC: 0.5518867924528302
F1: 0.5370507772393032

Running experiment 17/84

Running NeuralBench with Configuration:
device:		 cuda:0
state:		 None
approach:	 cnn10
category:	 None
batch_size:	 16
epochs:		 50
learning_rate:	 0.0001
seed:		 43
optimizer:	 KFACOptimizer
exclude cities:	 None

-----------------hi---------------
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_train.csv
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_evaluate.csv
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_evaluate.csv
Dev results at epoch 1:
UAR: 0.3166837291837292
ACC: 0.316711590296496
F1: 0.2796718951472742
train_loss: 2.320836492557023
val_loss: 1.8503122329711914

Dev results at epoch 2:
UAR: 0.3850771225771226
ACC: 0.3851078167115903
F1: 0.37152598701863637
train_loss: 1.5569076260886787
val_loss: 1.6124517917633057

Dev results at epoch 3:
UAR: 0.42448584948584955
ACC: 0.42452830188679247
F1: 0.4077358223133139
train_loss: 1.3545495416427122
val_loss: 1.5225523710250854

Dev results at epoch 4:
UAR: 0.46430521430521426
ACC: 0.4642857142857143
F1: 0.45232048142538545
train_loss: 1.221066345941843
val_loss: 1.3912254571914673

Dev results at epoch 5:
UAR: 0.4945707070707071
ACC: 0.4946091644204852
F1: 0.4861310280157519
train_loss: 1.0847158552171985
val_loss: 1.3592464923858643

Dev results at epoch 6:
UAR: 0.4692635817635818
ACC: 0.4693396226415094
F1: 0.44773218547740334
train_loss: 0.9897491937377335
val_loss: 1.4707502126693726

Dev results at epoch 7:
UAR: 0.4961768586768588
ACC: 0.49629380053908356
F1: 0.48605492608724055
train_loss: 0.9096328508949498
val_loss: 1.3860007524490356

Dev results at epoch 8:
UAR: 0.509029484029484
ACC: 0.5090970350404312
F1: 0.4963324121326885
train_loss: 0.8225008310218856
val_loss: 1.3757753372192383

Dev results at epoch 9:
UAR: 0.5259850759850759
ACC: 0.5259433962264151
F1: 0.5182697992163453
train_loss: 0.7376333394035578
val_loss: 1.3605871200561523

Dev results at epoch 10:
UAR: 0.5428337428337429
ACC: 0.5427897574123989
F1: 0.5295622724316379
train_loss: 0.689824000325263
val_loss: 1.3615864515304565

Dev results at epoch 11:
UAR: 0.5272192647192647
ACC: 0.5272911051212938
F1: 0.5120850363787736
train_loss: 0.5917898921246927
val_loss: 1.3940041065216064

Dev results at epoch 12:
UAR: 0.5413686413686414
ACC: 0.5414420485175202
F1: 0.5314520588719559
train_loss: 0.5583293381715695
val_loss: 1.4498836994171143

Dev results at epoch 13:
UAR: 0.5663572663572662
ACC: 0.5663746630727763
F1: 0.5625636340189807
train_loss: 0.5167023855062012
val_loss: 1.3796751499176025

Dev results at epoch 14:
UAR: 0.5447663572663572
ACC: 0.5448113207547169
F1: 0.5372220711690816
train_loss: 0.4795885045179523
val_loss: 1.4397739171981812

Dev results at epoch 15:
UAR: 0.5528414778414779
ACC: 0.5528975741239892
F1: 0.5509589181726254
train_loss: 0.42613910992479404
val_loss: 1.5090391635894775

Dev results at epoch 16:
UAR: 0.5578953953953953
ACC: 0.5579514824797843
F1: 0.550881125743324
train_loss: 0.38788573410605237
val_loss: 1.5781315565109253

Dev results at epoch 17:
UAR: 0.5646419146419147
ACC: 0.5646900269541779
F1: 0.5565318504350787
train_loss: 0.3555264820356481
val_loss: 1.5422006845474243

Dev results at epoch 18:
UAR: 0.5393689143689144
ACC: 0.5394204851752021
F1: 0.5315539981141295
train_loss: 0.33833116077671826
val_loss: 1.6171408891677856

Dev results at epoch 19:
UAR: 0.5453624078624079
ACC: 0.5454851752021563
F1: 0.5347910374687052
train_loss: 0.3362371011787571
val_loss: 1.7438137531280518

Dev results at epoch 20:
UAR: 0.5625602875602876
ACC: 0.5626684636118598
F1: 0.5594511337444711
train_loss: 0.30772903732067874
val_loss: 1.7038888931274414

Dev results at epoch 21:
UAR: 0.5568875693875694
ACC: 0.5569407008086253
F1: 0.5532217905660357
train_loss: 0.2980951454590703
val_loss: 1.8353440761566162

Dev results at epoch 22:
UAR: 0.5447379197379197
ACC: 0.5448113207547169
F1: 0.534316387734493
train_loss: 0.2776807392963378
val_loss: 1.887178897857666

Dev results at epoch 23:
UAR: 0.5609518609518609
ACC: 0.5609838274932615
F1: 0.5504078992625356
train_loss: 0.26681318834428286
val_loss: 1.9454665184020996

Dev results at epoch 24:
UAR: 0.555499817999818
ACC: 0.5555929919137467
F1: 0.5462677767293785
train_loss: 0.25286545740912014
val_loss: 1.9657511711120605

Dev results at epoch 25:
UAR: 0.5592228592228593
ACC: 0.5592991913746631
F1: 0.553527258858208
train_loss: 0.24635639698175288
val_loss: 2.0899927616119385

Dev results at epoch 26:
UAR: 0.5781042406042406
ACC: 0.578167115902965
F1: 0.5762842343262857
train_loss: 0.24063146184918652
val_loss: 1.7529594898223877

Dev results at epoch 27:
UAR: 0.5548889798889798
ACC: 0.5549191374663073
F1: 0.5390512795244398
train_loss: 0.21747496854625897
val_loss: 2.130337953567505

Dev results at epoch 28:
UAR: 0.554523842023842
ACC: 0.5545822102425876
F1: 0.5446695294602671
train_loss: 0.22074668337713677
val_loss: 2.146998167037964

Dev results at epoch 29:
UAR: 0.5609495859495859
ACC: 0.5609838274932615
F1: 0.5536301658408916
train_loss: 0.22905846422336534
val_loss: 2.1968882083892822

Dev results at epoch 30:
UAR: 0.5576235326235326
ACC: 0.5576145552560647
F1: 0.5473344524683604
train_loss: 0.20193280241844744
val_loss: 2.282688617706299

Dev results at epoch 31:
UAR: 0.5602329602329603
ACC: 0.5603099730458221
F1: 0.5494433835303466
train_loss: 0.19884507760393805
val_loss: 2.2695415019989014

Dev results at epoch 32:
UAR: 0.5673173173173173
ACC: 0.5673854447439353
F1: 0.5611571088878435
train_loss: 0.19971625186075678
val_loss: 2.330153703689575

Dev results at epoch 33:
UAR: 0.5680692055692056
ACC: 0.5680592991913747
F1: 0.5622209561427196
train_loss: 0.2036445219348956
val_loss: 2.212325096130371

Dev results at epoch 34:
UAR: 0.5609507234507235
ACC: 0.5609838274932615
F1: 0.5573836997567152
train_loss: 0.1722641766610324
val_loss: 2.4345929622650146

Dev results at epoch 35:
UAR: 0.5639673764673765
ACC: 0.5640161725067385
F1: 0.5612972664505242
train_loss: 0.18265714382332454
val_loss: 2.4672577381134033

Dev results at epoch 36:
UAR: 0.5511613886613886
ACC: 0.5512129380053908
F1: 0.5441566285726263
train_loss: 0.17238950459534602
val_loss: 2.5065901279449463

Dev results at epoch 37:
UAR: 0.5535080535080535
ACC: 0.5535714285714286
F1: 0.548540026267189
train_loss: 0.14966863504891526
val_loss: 2.726795196533203

Dev results at epoch 38:
UAR: 0.5299196924196924
ACC: 0.5299865229110512
F1: 0.5215199092043359
train_loss: 0.17270628220008585
val_loss: 2.654303550720215

Dev results at epoch 39:
UAR: 0.5491400491400492
ACC: 0.5491913746630728
F1: 0.546433929441013
train_loss: 0.19296201132277915
val_loss: 2.5363717079162598

Dev results at epoch 40:
UAR: 0.5518484393484393
ACC: 0.5518867924528302
F1: 0.5409467970060751
train_loss: 0.18030263139792416
val_loss: 2.6883177757263184

Dev results at epoch 41:
UAR: 0.5441213941213942
ACC: 0.5441374663072777
F1: 0.5338988918299086
train_loss: 0.17931136893221036
val_loss: 2.7062745094299316

Dev results at epoch 42:
UAR: 0.5494630994630995
ACC: 0.5495283018867925
F1: 0.5475330975452678
train_loss: 0.1693550764381958
val_loss: 2.6551597118377686

Dev results at epoch 43:
UAR: 0.535985985985986
ACC: 0.5360512129380054
F1: 0.5339761560877463
train_loss: 0.137191140708257
val_loss: 2.8039369583129883

Dev results at epoch 44:
UAR: 0.5464111839111839
ACC: 0.5464959568733153
F1: 0.5431596468779623
train_loss: 0.1877623414322051
val_loss: 2.875044107437134

Dev results at epoch 45:
UAR: 0.571036946036946
ACC: 0.5710916442048517
F1: 0.5639147100554947
train_loss: 0.17552836624518617
val_loss: 2.5847103595733643

Dev results at epoch 46:
UAR: 0.546055146055146
ACC: 0.5461590296495957
F1: 0.5355663395727538
train_loss: 0.15416767337422296
val_loss: 2.8158469200134277

Dev results at epoch 47:
UAR: 0.5629891254891255
ACC: 0.5630053908355795
F1: 0.5592152373715781
train_loss: 0.15923255512159226
val_loss: 2.5826973915100098

Dev results at epoch 48:
UAR: 0.5582707707707708
ACC: 0.558288409703504
F1: 0.5526408956679856
train_loss: 0.15247444299521137
val_loss: 2.9530982971191406

Dev results at epoch 49:
UAR: 0.561006461006461
ACC: 0.5609838274932615
F1: 0.5552837362859755
train_loss: 0.1536945639427723
val_loss: 2.686889886856079

Dev results at epoch 50:
UAR: 0.5649501774501775
ACC: 0.5650269541778976
F1: 0.5583627682587611
train_loss: 0.12532531602905334
val_loss: 2.809035062789917

Best dev results found at epoch 26:
UAR: 0.5781042406042406
ACC: 0.578167115902965
F1: 0.5762842343262857
train_loss: 0.24063146184918652
val_loss: 1.7529594898223877

Best test results:
UAR: 0.5781042406042406
ACC: 0.578167115902965
F1: 0.5762842343262857

Running experiment 18/84

Running NeuralBench with Configuration:
device:		 cuda:0
state:		 None
approach:	 cnn10
category:	 None
batch_size:	 16
epochs:		 50
learning_rate:	 0.0001
seed:		 43
optimizer:	 GDTUO-Adam-Adam
exclude cities:	 None

-----------------hi---------------
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_train.csv
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_evaluate.csv
//data/eihw-gpu5/milliman/DCASE/DCASE2020/metadata/evaluation_setup/fold1_evaluate.csv
Dev results at epoch 1:
UAR: 0.30744039494039493
ACC: 0.3076145552560647
F1: 0.25018751392534705
train_loss: 1.6764218018636672
val_loss: 2.1606006622314453

slurmstepd: error: *** JOB 29579 ON eihw-gpu7 CANCELLED AT 2023-06-07T13:40:10 ***
